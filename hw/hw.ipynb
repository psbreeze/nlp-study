{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install graphviz\n",
    "# conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_rawdata():\n",
    "    ret = []\n",
    "    \n",
    "    f = open(\"crx.data\", 'r')\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: \n",
    "            break\n",
    "        line = line.replace('\\n', '')\n",
    "        ret.append(line.split(','))\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def to_onehot_vec(data_range, data):\n",
    "    ret = []\n",
    "    found = False\n",
    "    \n",
    "    for i in range(len(data_range)):\n",
    "        if (data_range[i] == data):\n",
    "            found = True\n",
    "            ret.append(1)\n",
    "        else:\n",
    "            ret.append(0)\n",
    "    \n",
    "    if (found == False):\n",
    "        print(\"Error!: \" + str(data_range) + \" real: \"+data)\n",
    "        \n",
    "    return ret\n",
    "\n",
    "def to_continuous(data):\n",
    "    if (data == '?'):\n",
    "        return 999\n",
    "    \n",
    "    return float(data)\n",
    "\n",
    "def preprocess(data):\n",
    "    ret = []\n",
    "    \n",
    "    for d in data:\n",
    "        vec = []\n",
    "        \n",
    "        # A1: b, a.\n",
    "        vec.extend(to_onehot_vec(['b','a','?'], d[0]))\n",
    "        \n",
    "        # A2:\tcontinuous.\n",
    "        vec.append(to_continuous(d[1]))\n",
    "        \n",
    "        # A3:\tcontinuous.\n",
    "        vec.append(to_continuous(d[2]))\n",
    "        \n",
    "        # A4:\tu, y, l, t.\n",
    "        vec.extend(to_onehot_vec(['u', 'y', 'l', 't','?'], d[3]))\n",
    "        \n",
    "        # A5:\tg, p, gg.\n",
    "        vec.extend(to_onehot_vec(['g', 'p', 'gg','?'], d[4]))\n",
    "        \n",
    "        # A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
    "        vec.extend(to_onehot_vec(['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff','?'], d[5]))\n",
    "        \n",
    "        # A7:\tv, h, bb, j, n, z, dd, ff, o.\n",
    "        vec.extend(to_onehot_vec(['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o','?'], d[6]))\n",
    "        \n",
    "        # A8:\tcontinuous.\n",
    "        vec.append(to_continuous(d[7]))\n",
    "        \n",
    "        # A9:\tt, f.\n",
    "        vec.extend(to_onehot_vec(['t', 'f','?'], d[8]))\n",
    "        \n",
    "        # A10:\tt, f.\n",
    "        vec.extend(to_onehot_vec(['t', 'f','?'], d[9]))\n",
    "        \n",
    "        # A11:\tcontinuous.\n",
    "        vec.append(to_continuous(d[10]))\n",
    "        \n",
    "        # A12:\tt, f..\n",
    "        vec.extend(to_onehot_vec(['t', 'f','?'], d[11]))\n",
    "        \n",
    "        # A13:\tg, p, s.\n",
    "        vec.extend(to_onehot_vec(['g', 'p', 's','?'], d[12]))\n",
    "        \n",
    "        # A14:\tcontinuous.\n",
    "        vec.append(to_continuous(d[13]))\n",
    "        \n",
    "        # A15:\tcontinuous.\n",
    "        vec.append(to_continuous(d[14]))\n",
    "        \n",
    "        # A16: +,-         (class attribute)\n",
    "        if (d[15] == '+'):\n",
    "            vec.append(1)\n",
    "        else:\n",
    "            vec.append(0)\n",
    "        \n",
    "        ret.append(np.array(vec))\n",
    "        \n",
    "    return np.array(ret)\n",
    "\n",
    "def load():\n",
    "    return preprocess(load_rawdata())\n",
    "\n",
    "data = load()\n",
    "X, y = np.split(data,[-1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 1.000\n",
      "테스트 세트 정확도: 0.807\n"
     ]
    }
   ],
   "source": [
    "# 2.1. CanonicalModels\n",
    "# decision tree\n",
    "# ref: https://scikit-learn.org/stable/modules/tree.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def CanonicalModels_2_1_decision_tree():\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "    \n",
    "    return clf\n",
    "\n",
    "decision_tree_model = CanonicalModels_2_1_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.976\n",
      "테스트 세트 정확도: 0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psbreeze\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 2.1. CanonicalModels\n",
    "# Support Vector Machine\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def CanonicalModels_2_1_SVM():\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "    \n",
    "    return clf\n",
    "\n",
    "svm_model = CanonicalModels_2_1_SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.874\n",
      "테스트 세트 정확도: 0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psbreeze\\Anaconda3\\envs\\test\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 2.2. Committee Machines\n",
    "# Random Forest\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def CommitteeMachines_2_2_RandomForest():\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "    \n",
    "    return clf\n",
    "\n",
    "random_forest_model = CommitteeMachines_2_2_RandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psbreeze\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.937\n",
      "테스트 세트 정확도: 0.825\n"
     ]
    }
   ],
   "source": [
    "# 2.2. Committee Machines\n",
    "# Ada Boost\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def CommitteeMachines_2_2_AdaBoost():\n",
    "    clf = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "    \n",
    "    return clf\n",
    "\n",
    "ada_boost_model = CommitteeMachines_2_2_AdaBoost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26000/462 ...  - loss: 140.0463 - acc: 0.1094\n",
      "52000/462 ...  - loss: 33.7205 - acc: 0.2266\n",
      "훈련 세트 정확도: 0.266\n",
      "테스트 세트 정확도: 0.272\n"
     ]
    }
   ],
   "source": [
    "# 2.3. Deep Learning Model\n",
    "# KerasClassification\n",
    "# ref: https://keras.io/scikit-learn-api/\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class NBatchLogger(Callback):\n",
    "    def __init__(self, display):\n",
    "        self.seen = 0\n",
    "        self.display = display\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.seen += logs.get('size', 0)\n",
    "        if self.seen % self.display == 0:\n",
    "            metrics_log = ''\n",
    "            for k in self.params['metrics']:\n",
    "                if k in logs:\n",
    "                    val = logs[k]\n",
    "                    if abs(val) > 1e-3:\n",
    "                        metrics_log += ' - %s: %.4f' % (k, val)\n",
    "                    else:\n",
    "                        metrics_log += ' - %s: %.4e' % (k, val)\n",
    "            print('{}/{} ... {}'.format(self.seen,\n",
    "                                        self.params['samples'],\n",
    "                                        metrics_log))\n",
    "            \n",
    "def DeepLearningModel_2_3_baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=56, activation='relu'))\n",
    "    model.add(Dense(10, input_dim=10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def DeepLearningModel_2_3_KerasClassifier():\n",
    "    # create model\n",
    "    clf = KerasClassifier(build_fn=DeepLearningModel_2_3_baseline_model, epochs=1500, batch_size=128, verbose=0)\n",
    "    clf.fit(X_train, y_train,batch_size=128,callbacks=[NBatchLogger(display=1000)])\n",
    "    print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "DeepLearningModel_2_3_KerasClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
