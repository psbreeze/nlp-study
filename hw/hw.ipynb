{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install graphviz\n",
    "# conda install python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_rawdata():\n",
    "    ret = []\n",
    "    \n",
    "    f = open(\"crx.data\", 'r')\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line: \n",
    "            break\n",
    "        line = line.replace('\\n', '')\n",
    "        ret.append(line.split(','))\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def to_onehot_vec(data_range, data):\n",
    "    ret = []\n",
    "    found = False\n",
    "    \n",
    "    for i in range(len(data_range)):\n",
    "        if (data_range[i] == data):\n",
    "            found = True\n",
    "            ret.append(1)\n",
    "        else:\n",
    "            ret.append(0)\n",
    "    \n",
    "    if (found == False):\n",
    "        print(\"Error!: \" + str(data_range) + \" real: \"+data)\n",
    "        \n",
    "    return ret\n",
    "\n",
    "def to_continuous(data):\n",
    "    if (data == '?'):\n",
    "        return 999\n",
    "    \n",
    "    return float(data)\n",
    "\n",
    "def preprocess(data):\n",
    "    ret = []\n",
    "    \n",
    "    for d in data:\n",
    "        vec = []\n",
    "        \n",
    "        # A1: b, a.\n",
    "        vec.extend(to_onehot_vec(['b','a','?'], d[0]))\n",
    "        \n",
    "        # A2:\tcontinuous.\n",
    "        vec.append(to_continuous(d[1]))\n",
    "        \n",
    "        # A3:\tcontinuous.\n",
    "        vec.append(to_continuous(d[2]))\n",
    "        \n",
    "        # A4:\tu, y, l, t.\n",
    "        vec.extend(to_onehot_vec(['u', 'y', 'l', 't','?'], d[3]))\n",
    "        \n",
    "        # A5:\tg, p, gg.\n",
    "        vec.extend(to_onehot_vec(['g', 'p', 'gg','?'], d[4]))\n",
    "        \n",
    "        # A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
    "        vec.extend(to_onehot_vec(['c', 'd', 'cc', 'i', 'j', 'k', 'm', 'r', 'q', 'w', 'x', 'e', 'aa', 'ff','?'], d[5]))\n",
    "        \n",
    "        # A7:\tv, h, bb, j, n, z, dd, ff, o.\n",
    "        vec.extend(to_onehot_vec(['v', 'h', 'bb', 'j', 'n', 'z', 'dd', 'ff', 'o','?'], d[6]))\n",
    "        \n",
    "        # A8:\tcontinuous.\n",
    "        vec.append(to_continuous(d[7]))\n",
    "        \n",
    "        # A9:\tt, f.\n",
    "        vec.extend(to_onehot_vec(['t', 'f','?'], d[8]))\n",
    "        \n",
    "        # A10:\tt, f.\n",
    "        vec.extend(to_onehot_vec(['t', 'f','?'], d[9]))\n",
    "        \n",
    "        # A11:\tcontinuous.\n",
    "        vec.append(to_continuous(d[10]))\n",
    "        \n",
    "        # A12:\tt, f..\n",
    "        vec.extend(to_onehot_vec(['t', 'f','?'], d[11]))\n",
    "        \n",
    "        # A13:\tg, p, s.\n",
    "        vec.extend(to_onehot_vec(['g', 'p', 's','?'], d[12]))\n",
    "        \n",
    "        # A14:\tcontinuous.\n",
    "        vec.append(to_continuous(d[13]))\n",
    "        \n",
    "        # A15:\tcontinuous.\n",
    "        vec.append(to_continuous(d[14]))\n",
    "        \n",
    "        # A16: +,-         (class attribute)\n",
    "        if (d[15] == '+'):\n",
    "            vec.append(1)\n",
    "        else:\n",
    "            vec.append(0)\n",
    "        \n",
    "        ret.append(np.array(vec))\n",
    "        \n",
    "    return np.array(ret)\n",
    "\n",
    "def load():\n",
    "    return preprocess(load_rawdata())\n",
    "\n",
    "def get_tp(y_test, y_pred):\n",
    "    tp = 0\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if (y_test[i] == 1 and y_pred[i] == 1):\n",
    "            tp = tp + 1\n",
    "            \n",
    "    return tp\n",
    "\n",
    "def get_tn(y_test, y_pred):\n",
    "    tn = 0\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if (y_test[i] == 0 and y_pred[i] == 0):\n",
    "            tn = tn + 1\n",
    "            \n",
    "    return tn\n",
    "\n",
    "def get_fp(y_test, y_pred):\n",
    "    fp = 0\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if (y_test[i] == 0 and y_pred[i] == 1):\n",
    "            fp = fp + 1\n",
    "            \n",
    "    return fp\n",
    "\n",
    "def get_fn(y_test, y_pred):\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if (y_test[i] == 1 and y_pred[i] == 0):\n",
    "            fn = fn + 1\n",
    "            \n",
    "    return fn\n",
    "\n",
    "def get_accuracy(y_test, y_pred):\n",
    "    tp = get_tp(y_test, y_pred)\n",
    "    tn = get_tn(y_test, y_pred)\n",
    "    fp = get_fp(y_test, y_pred)\n",
    "    fn = get_fn(y_test, y_pred)\n",
    "    \n",
    "    return (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "def get_precision(y_test, y_pred):\n",
    "    tp = get_tp(y_test, y_pred)\n",
    "    fp = get_fp(y_test, y_pred)\n",
    "    \n",
    "    if (tp + fp == 0):\n",
    "        return 0\n",
    "    \n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def get_recall(y_test, y_pred):\n",
    "    tp = get_tp(y_test, y_pred)\n",
    "    fn = get_fn(y_test, y_pred)\n",
    "    \n",
    "    if (tp + fn == 0):\n",
    "        return 0\n",
    "    \n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def get_f1(y_test, y_pred):\n",
    "    precision = get_precision(y_test, y_pred)\n",
    "    recall = get_recall(y_test, y_pred)\n",
    "    \n",
    "    if (precision + recall == 0):\n",
    "        return 0\n",
    "    \n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "def evaluation(y_test, y_pred):\n",
    "    print(\"My Accuracy :\\t\" + str(get_accuracy(y_test, y_pred)) + \"\\t\\t\" + \"sklearn Accuracy :\\t\"+str(accuracy_score(y_test, y_pred)))\n",
    "    print(\"My Precision:\\t\" + str(get_precision(y_test, y_pred)) + \"\\t\\t\" + \"sklearn Precision:\\t\"+str(precision_score(y_test, y_pred)))\n",
    "    print(\"My Recall   :\\t\" + str(get_recall(y_test, y_pred)) + \"\\t\\t\" + \"sklearn Recall   :\\t\"+str(recall_score(y_test, y_pred)))\n",
    "    print(\"My F1       :\\t\" + str(get_f1(y_test, y_pred)) + \"\\t\\t\" + \"sklearn F1       :\\t\"+str(f1_score(y_test, y_pred)))\n",
    "    \n",
    "data = load()\n",
    "X, y = np.split(data,[-1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Accuracy :\t0.8070175438596491\t\tsklearn Accuracy :\t0.8070175438596491\n",
      "My Precision:\t0.797979797979798\t\tsklearn Precision:\t0.797979797979798\n",
      "My Recall   :\t0.7669902912621359\t\tsklearn Recall   :\t0.7669902912621359\n",
      "My F1       :\t0.7821782178217821\t\tsklearn F1       :\t0.7821782178217821\n"
     ]
    }
   ],
   "source": [
    "# 2.1. CanonicalModels\n",
    "# decision tree\n",
    "# ref: https://scikit-learn.org/stable/modules/tree.html\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def CanonicalModels_2_1_decision_tree():\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf.predict(X_test)\n",
    "\n",
    "evaluation(y_test, CanonicalModels_2_1_decision_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Accuracy :\t0.5263157894736842\t\tsklearn Accuracy :\t0.5263157894736842\n",
      "My Precision:\t0.4358974358974359\t\tsklearn Precision:\t0.4358974358974359\n",
      "My Recall   :\t0.1650485436893204\t\tsklearn Recall   :\t0.1650485436893204\n",
      "My F1       :\t0.23943661971830985\t\tsklearn F1       :\t0.23943661971830985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psbreeze\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 2.1. CanonicalModels\n",
    "# Support Vector Machine\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def CanonicalModels_2_1_SVM():\n",
    "    clf = SVC(gamma='auto')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf.predict(X_test)\n",
    "\n",
    "evaluation(y_test, CanonicalModels_2_1_SVM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Accuracy :\t0.8640350877192983\t\tsklearn Accuracy :\t0.8640350877192983\n",
      "My Precision:\t0.9\t\tsklearn Precision:\t0.9\n",
      "My Recall   :\t0.7864077669902912\t\tsklearn Recall   :\t0.7864077669902912\n",
      "My F1       :\t0.8393782383419689\t\tsklearn F1       :\t0.8393782383419689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psbreeze\\Anaconda3\\envs\\test\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 2.2. Committee Machines\n",
    "# Random Forest\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def CommitteeMachines_2_2_RandomForest():\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf.predict(X_test)\n",
    "\n",
    "evaluation(y_test, CommitteeMachines_2_2_RandomForest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Accuracy :\t0.8245614035087719\t\tsklearn Accuracy :\t0.8245614035087719\n",
      "My Precision:\t0.8181818181818182\t\tsklearn Precision:\t0.8181818181818182\n",
      "My Recall   :\t0.7864077669902912\t\tsklearn Recall   :\t0.7864077669902912\n",
      "My F1       :\t0.801980198019802\t\tsklearn F1       :\t0.801980198019802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psbreeze\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 2.2. Committee Machines\n",
    "# Ada Boost\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def CommitteeMachines_2_2_AdaBoost():\n",
    "    clf = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    return clf.predict(X_test)\n",
    "\n",
    "evaluation(y_test, CommitteeMachines_2_2_AdaBoost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26000/462 ...  - loss: 6.0595 - acc: 0.3906\n",
      "52000/462 ...  - loss: 1.0678 - acc: 0.5312\n",
      "78000/462 ...  - loss: 0.5167 - acc: 0.5859\n",
      "231000/462 ...  - loss: 0.2287 - acc: 0.7051\n",
      "257000/462 ...  - loss: 0.2047 - acc: 0.7188\n",
      "283000/462 ...  - loss: 0.2259 - acc: 0.7891\n",
      "309000/462 ...  - loss: 0.6441 - acc: 0.7734\n",
      "462000/462 ...  - loss: 0.1876 - acc: 0.8205\n",
      "488000/462 ...  - loss: 0.1105 - acc: 0.8359\n",
      "514000/462 ...  - loss: 0.2799 - acc: 0.7812\n",
      "540000/462 ...  - loss: 0.1255 - acc: 0.8359\n",
      "693000/462 ...  - loss: 0.9759 - acc: 0.5641\n",
      "My Accuracy :\t0.6710526315789473\t\tsklearn Accuracy :\t0.6710526315789473\n",
      "My Precision:\t0.6666666666666666\t\tsklearn Precision:\t0.6666666666666666\n",
      "My Recall   :\t0.5436893203883495\t\tsklearn Recall   :\t0.5436893203883495\n",
      "My F1       :\t0.5989304812834224\t\tsklearn F1       :\t0.5989304812834224\n"
     ]
    }
   ],
   "source": [
    "# 2.3. Deep Learning Model\n",
    "# KerasClassification\n",
    "# ref: https://keras.io/scikit-learn-api/\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class NBatchLogger(Callback):\n",
    "    def __init__(self, display):\n",
    "        self.seen = 0\n",
    "        self.display = display\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.seen += logs.get('size', 0)\n",
    "        if self.seen % self.display == 0:\n",
    "            metrics_log = ''\n",
    "            for k in self.params['metrics']:\n",
    "                if k in logs:\n",
    "                    val = logs[k]\n",
    "                    if abs(val) > 1e-3:\n",
    "                        metrics_log += ' - %s: %.4f' % (k, val)\n",
    "                    else:\n",
    "                        metrics_log += ' - %s: %.4e' % (k, val)\n",
    "            print('{}/{} ... {}'.format(self.seen,\n",
    "                                        self.params['samples'],\n",
    "                                        metrics_log))\n",
    "            \n",
    "def DeepLearningModel_2_3_baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=56, activation='relu'))\n",
    "    model.add(Dense(10, input_dim=10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def DeepLearningModel_2_3_KerasClassifier():\n",
    "    # create model\n",
    "    clf = KerasClassifier(build_fn=DeepLearningModel_2_3_baseline_model, epochs=1500, batch_size=128, verbose=0)\n",
    "    clf.fit(X_train, y_train,batch_size=128,callbacks=[NBatchLogger(display=1000)])\n",
    "    \n",
    "    return clf.predict(X_test)\n",
    "\n",
    "evaluation(y_test, DeepLearningModel_2_3_KerasClassifier())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
