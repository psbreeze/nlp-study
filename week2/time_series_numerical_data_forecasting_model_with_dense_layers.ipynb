{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.visible_device_list='0'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.25\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "signal_data = np.cos(np.arange(1600)*(20*np.pi/1000))[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_x = np.arange(1600)\n",
    "plot_y = signal_data\n",
    "plt.plot(plot_x, plot_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset from generated data\n",
    "def create_dataset(signal_data, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(signal_data) - look_back):\n",
    "        dataX.append(signal_data[i:(i+look_back), 0])\n",
    "        dataY.append(signal_data[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -1.0~1.0 --> 0.0~1.0  set look_back = 40 \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "look_back = 40 \n",
    "\n",
    "# data preprocessing\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "signal_data = scaler.fit_transform(signal_data)\n",
    "\n",
    "# data split\n",
    "train = signal_data[0:800]\n",
    "val = signal_data[800:1200]\n",
    "test = signal_data[1200:]\n",
    "\n",
    "# dataset creation\n",
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_val, y_val = create_dataset(val, look_back)\n",
    "x_test, y_test = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset preprocessing\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "x_train = np.squeeze(x_train) \n",
    "x_val = np.squeeze(x_val)\n",
    "x_test = np.squeeze(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# model design\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=40, activation='relu'))\n",
    "model.add(Dropout(0.3)) \n",
    "for i in range(2):\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adagrad')\n",
    "hist = model.fit(x_train, y_train, epochs=200, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train \n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 0.15)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train Score: ', trainScore)\n",
    "valScore = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Validation Score: ', valScore)\n",
    "testScore = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Score:', testScore) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_ahead = 250\n",
    "xhat = x_test[0, None]\n",
    "predictions = np.zeros((look_ahead, 1))\n",
    "for i in range(look_ahead):     \n",
    "    prediction = model.predict(xhat, batch_size=32)\n",
    "    predictions[i] = prediction \n",
    "    xhat = np.hstack([xhat[:,1:], prediction])\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(np.arange(look_ahead), predictions, 'r', label='prediction')\n",
    "plt.plot(np.arange(look_ahead), y_test[:look_ahead], label='test function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
