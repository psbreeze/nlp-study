{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.visible_device_list='2'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.25\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "signal_data = np.cos(np.arange(1600)*(20*np.pi/1000))[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa34c52f0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_x = np.arange(1600)\n",
    "plot_y = signal_data\n",
    "plt.plot(plot_x, plot_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset from generated data\n",
    "def create_dataset(signal_data, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(signal_data) - look_back):\n",
    "        dataX.append(signal_data[i:(i+look_back), 0])\n",
    "        dataY.append(signal_data[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -1.0~1.0 --> 0.0~1.0  set look_back = 40 \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "look_back = 40 \n",
    "\n",
    "# data preprocessing\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "signal_data = scaler.fit_transform(signal_data)\n",
    "\n",
    "# data split\n",
    "train = signal_data[0:800]\n",
    "val = signal_data[800:1200]\n",
    "test = signal_data[1200:]\n",
    "\n",
    "# dataset creation\n",
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_val, y_val = create_dataset(val, look_back)\n",
    "x_test, y_test = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset preprocessing\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "x_train = np.squeeze(x_train) \n",
    "x_val = np.squeeze(x_val)\n",
    "x_test = np.squeeze(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# model design\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=40, activation='relu'))\n",
    "model.add(Dropout(0.3)) \n",
    "for i in range(4):\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 760 samples, validate on 360 samples\n",
      "Epoch 1/2000\n",
      "760/760 [==============================] - 1s 1ms/step - loss: 0.3331 - val_loss: 0.1481\n",
      "Epoch 2/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.1520 - val_loss: 0.0525\n",
      "Epoch 3/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.1088 - val_loss: 0.0623\n",
      "Epoch 4/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0982 - val_loss: 0.0496\n",
      "Epoch 5/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0836 - val_loss: 0.0462\n",
      "Epoch 6/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0687 - val_loss: 0.0443\n",
      "Epoch 7/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0643 - val_loss: 0.0401\n",
      "Epoch 8/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0580 - val_loss: 0.0465\n",
      "Epoch 9/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0567 - val_loss: 0.0314\n",
      "Epoch 10/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0586 - val_loss: 0.0470\n",
      "Epoch 11/2000\n",
      "760/760 [==============================] - 0s 309us/step - loss: 0.0503 - val_loss: 0.0625\n",
      "Epoch 12/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0528 - val_loss: 0.0436\n",
      "Epoch 13/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0451 - val_loss: 0.0403\n",
      "Epoch 14/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0444 - val_loss: 0.0479\n",
      "Epoch 15/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0396 - val_loss: 0.0652\n",
      "Epoch 16/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0390 - val_loss: 0.0422\n",
      "Epoch 17/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0373 - val_loss: 0.0531\n",
      "Epoch 18/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0368 - val_loss: 0.0495\n",
      "Epoch 19/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0357 - val_loss: 0.0591\n",
      "Epoch 20/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0359 - val_loss: 0.0401\n",
      "Epoch 21/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0351 - val_loss: 0.0486\n",
      "Epoch 22/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0336 - val_loss: 0.0467\n",
      "Epoch 23/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0276 - val_loss: 0.0418\n",
      "Epoch 24/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0273 - val_loss: 0.0381\n",
      "Epoch 25/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0289 - val_loss: 0.0398\n",
      "Epoch 26/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0296 - val_loss: 0.0458\n",
      "Epoch 27/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0278 - val_loss: 0.0530\n",
      "Epoch 28/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0264 - val_loss: 0.0414\n",
      "Epoch 29/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0255 - val_loss: 0.0531\n",
      "Epoch 30/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0282 - val_loss: 0.0464\n",
      "Epoch 31/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0267 - val_loss: 0.0416\n",
      "Epoch 32/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0229 - val_loss: 0.0445\n",
      "Epoch 33/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0238 - val_loss: 0.0433\n",
      "Epoch 34/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0247 - val_loss: 0.0403\n",
      "Epoch 35/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0222 - val_loss: 0.0398\n",
      "Epoch 36/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0218 - val_loss: 0.0373\n",
      "Epoch 37/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0229 - val_loss: 0.0397\n",
      "Epoch 38/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0206 - val_loss: 0.0380\n",
      "Epoch 39/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0218 - val_loss: 0.0375\n",
      "Epoch 40/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0212 - val_loss: 0.0453\n",
      "Epoch 41/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0201 - val_loss: 0.0386\n",
      "Epoch 42/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0221 - val_loss: 0.0396\n",
      "Epoch 43/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0206 - val_loss: 0.0401\n",
      "Epoch 44/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0186 - val_loss: 0.0408\n",
      "Epoch 45/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0184 - val_loss: 0.0472\n",
      "Epoch 46/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0212 - val_loss: 0.0395\n",
      "Epoch 47/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0200 - val_loss: 0.0331\n",
      "Epoch 48/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0203 - val_loss: 0.0305\n",
      "Epoch 49/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0216 - val_loss: 0.0369\n",
      "Epoch 50/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0187 - val_loss: 0.0379\n",
      "Epoch 51/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0174 - val_loss: 0.0412\n",
      "Epoch 52/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0192 - val_loss: 0.0329\n",
      "Epoch 53/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0185 - val_loss: 0.0354\n",
      "Epoch 54/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0178 - val_loss: 0.0418\n",
      "Epoch 55/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0166 - val_loss: 0.0388\n",
      "Epoch 56/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0188 - val_loss: 0.0332\n",
      "Epoch 57/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0171 - val_loss: 0.0355\n",
      "Epoch 58/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0148 - val_loss: 0.0342\n",
      "Epoch 59/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0162 - val_loss: 0.0400\n",
      "Epoch 60/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0168 - val_loss: 0.0270\n",
      "Epoch 61/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0162 - val_loss: 0.0345\n",
      "Epoch 62/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0164 - val_loss: 0.0318\n",
      "Epoch 63/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0160 - val_loss: 0.0376\n",
      "Epoch 64/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0174 - val_loss: 0.0357\n",
      "Epoch 65/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0152 - val_loss: 0.0348\n",
      "Epoch 66/2000\n",
      "760/760 [==============================] - 0s 319us/step - loss: 0.0160 - val_loss: 0.0328\n",
      "Epoch 67/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0155 - val_loss: 0.0318\n",
      "Epoch 68/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0168 - val_loss: 0.0305\n",
      "Epoch 69/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0168 - val_loss: 0.0354\n",
      "Epoch 70/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0156 - val_loss: 0.0286\n",
      "Epoch 71/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0144 - val_loss: 0.0331\n",
      "Epoch 72/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0152 - val_loss: 0.0344\n",
      "Epoch 73/2000\n",
      "760/760 [==============================] - 0s 306us/step - loss: 0.0153 - val_loss: 0.0297\n",
      "Epoch 74/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0150 - val_loss: 0.0312\n",
      "Epoch 75/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0150 - val_loss: 0.0348\n",
      "Epoch 76/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0154 - val_loss: 0.0353\n",
      "Epoch 77/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0148 - val_loss: 0.0260\n",
      "Epoch 78/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0140 - val_loss: 0.0292\n",
      "Epoch 79/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0135 - val_loss: 0.0299\n",
      "Epoch 80/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0135 - val_loss: 0.0309\n",
      "Epoch 81/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0141 - val_loss: 0.0344\n",
      "Epoch 82/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0140 - val_loss: 0.0329\n",
      "Epoch 83/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0134 - val_loss: 0.0285\n",
      "Epoch 84/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0122 - val_loss: 0.0317\n",
      "Epoch 85/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0146 - val_loss: 0.0318\n",
      "Epoch 86/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0145 - val_loss: 0.0261\n",
      "Epoch 87/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0132 - val_loss: 0.0255\n",
      "Epoch 88/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0150 - val_loss: 0.0310\n",
      "Epoch 89/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0145 - val_loss: 0.0309\n",
      "Epoch 90/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0133 - val_loss: 0.0314\n",
      "Epoch 91/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0132 - val_loss: 0.0275\n",
      "Epoch 92/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0126 - val_loss: 0.0303\n",
      "Epoch 93/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0131 - val_loss: 0.0331\n",
      "Epoch 94/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0142 - val_loss: 0.0300\n",
      "Epoch 95/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0158 - val_loss: 0.0265\n",
      "Epoch 96/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0124 - val_loss: 0.0343\n",
      "Epoch 97/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0120 - val_loss: 0.0305\n",
      "Epoch 98/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0129 - val_loss: 0.0282\n",
      "Epoch 99/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0123 - val_loss: 0.0330\n",
      "Epoch 100/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0143 - val_loss: 0.0303\n",
      "Epoch 101/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0127 - val_loss: 0.0325\n",
      "Epoch 102/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0131 - val_loss: 0.0356\n",
      "Epoch 103/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0141 - val_loss: 0.0327\n",
      "Epoch 104/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0135 - val_loss: 0.0307\n",
      "Epoch 105/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0140 - val_loss: 0.0255\n",
      "Epoch 106/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0127 - val_loss: 0.0289\n",
      "Epoch 107/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0106 - val_loss: 0.0293\n",
      "Epoch 108/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0116 - val_loss: 0.0301\n",
      "Epoch 109/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0105 - val_loss: 0.0270\n",
      "Epoch 110/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0121 - val_loss: 0.0318\n",
      "Epoch 111/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0124 - val_loss: 0.0310\n",
      "Epoch 112/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0125 - val_loss: 0.0336\n",
      "Epoch 113/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0122 - val_loss: 0.0326\n",
      "Epoch 114/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0135 - val_loss: 0.0277\n",
      "Epoch 115/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0124 - val_loss: 0.0309\n",
      "Epoch 116/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0135 - val_loss: 0.0332\n",
      "Epoch 117/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0119 - val_loss: 0.0338\n",
      "Epoch 118/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0115 - val_loss: 0.0324\n",
      "Epoch 119/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0117 - val_loss: 0.0311\n",
      "Epoch 120/2000\n",
      "760/760 [==============================] - 0s 261us/step - loss: 0.0113 - val_loss: 0.0308\n",
      "Epoch 121/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0124 - val_loss: 0.0277\n",
      "Epoch 122/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0118 - val_loss: 0.0305\n",
      "Epoch 123/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0118 - val_loss: 0.0301\n",
      "Epoch 124/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0129 - val_loss: 0.0307\n",
      "Epoch 125/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0122 - val_loss: 0.0312\n",
      "Epoch 126/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0113 - val_loss: 0.0277\n",
      "Epoch 127/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0117 - val_loss: 0.0269\n",
      "Epoch 128/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0113 - val_loss: 0.0300\n",
      "Epoch 129/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0120 - val_loss: 0.0325\n",
      "Epoch 130/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0113 - val_loss: 0.0318\n",
      "Epoch 131/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0118 - val_loss: 0.0324\n",
      "Epoch 132/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0122 - val_loss: 0.0272\n",
      "Epoch 133/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0115 - val_loss: 0.0243\n",
      "Epoch 134/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0108 - val_loss: 0.0292\n",
      "Epoch 135/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0120 - val_loss: 0.0298\n",
      "Epoch 136/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0117 - val_loss: 0.0273\n",
      "Epoch 137/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0113 - val_loss: 0.0312\n",
      "Epoch 138/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0114 - val_loss: 0.0302\n",
      "Epoch 139/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0119 - val_loss: 0.0286\n",
      "Epoch 140/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0111 - val_loss: 0.0300\n",
      "Epoch 141/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0124 - val_loss: 0.0362\n",
      "Epoch 142/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0128 - val_loss: 0.0260\n",
      "Epoch 143/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0121 - val_loss: 0.0304\n",
      "Epoch 144/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0127 - val_loss: 0.0271\n",
      "Epoch 145/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0118 - val_loss: 0.0305\n",
      "Epoch 146/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0117 - val_loss: 0.0314\n",
      "Epoch 147/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0106 - val_loss: 0.0325\n",
      "Epoch 148/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0112 - val_loss: 0.0314\n",
      "Epoch 149/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0122 - val_loss: 0.0354\n",
      "Epoch 150/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0115 - val_loss: 0.0317\n",
      "Epoch 151/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0110 - val_loss: 0.0348\n",
      "Epoch 152/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0109 - val_loss: 0.0270\n",
      "Epoch 153/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0110 - val_loss: 0.0336\n",
      "Epoch 154/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0124 - val_loss: 0.0271\n",
      "Epoch 155/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 304us/step - loss: 0.0114 - val_loss: 0.0278\n",
      "Epoch 156/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0116 - val_loss: 0.0268\n",
      "Epoch 157/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0105 - val_loss: 0.0270\n",
      "Epoch 158/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0111 - val_loss: 0.0244\n",
      "Epoch 159/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0113 - val_loss: 0.0272\n",
      "Epoch 160/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0118 - val_loss: 0.0306\n",
      "Epoch 161/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0113 - val_loss: 0.0297\n",
      "Epoch 162/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0111 - val_loss: 0.0282\n",
      "Epoch 163/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0123 - val_loss: 0.0314\n",
      "Epoch 164/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0121 - val_loss: 0.0268\n",
      "Epoch 165/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0108 - val_loss: 0.0259\n",
      "Epoch 166/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0118 - val_loss: 0.0296\n",
      "Epoch 167/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0112 - val_loss: 0.0314\n",
      "Epoch 168/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0107 - val_loss: 0.0287\n",
      "Epoch 169/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0096 - val_loss: 0.0284\n",
      "Epoch 170/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0108 - val_loss: 0.0327\n",
      "Epoch 171/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0089 - val_loss: 0.0279\n",
      "Epoch 172/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0112 - val_loss: 0.0290\n",
      "Epoch 173/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0105 - val_loss: 0.0285\n",
      "Epoch 174/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0110 - val_loss: 0.0365\n",
      "Epoch 175/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0101 - val_loss: 0.0334\n",
      "Epoch 176/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0104 - val_loss: 0.0324\n",
      "Epoch 177/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0110 - val_loss: 0.0321\n",
      "Epoch 178/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0101 - val_loss: 0.0328\n",
      "Epoch 179/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0104 - val_loss: 0.0339\n",
      "Epoch 180/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0101 - val_loss: 0.0316\n",
      "Epoch 181/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0104 - val_loss: 0.0290\n",
      "Epoch 182/2000\n",
      "760/760 [==============================] - 0s 321us/step - loss: 0.0098 - val_loss: 0.0287\n",
      "Epoch 183/2000\n",
      "760/760 [==============================] - 0s 306us/step - loss: 0.0102 - val_loss: 0.0275\n",
      "Epoch 184/2000\n",
      "760/760 [==============================] - 0s 309us/step - loss: 0.0103 - val_loss: 0.0288\n",
      "Epoch 185/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0098 - val_loss: 0.0280\n",
      "Epoch 186/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0103 - val_loss: 0.0318\n",
      "Epoch 187/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0106 - val_loss: 0.0299\n",
      "Epoch 188/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0105 - val_loss: 0.0289\n",
      "Epoch 189/2000\n",
      "760/760 [==============================] - 0s 328us/step - loss: 0.0103 - val_loss: 0.0289\n",
      "Epoch 190/2000\n",
      "760/760 [==============================] - 0s 319us/step - loss: 0.0110 - val_loss: 0.0298\n",
      "Epoch 191/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0095 - val_loss: 0.0318\n",
      "Epoch 192/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0102 - val_loss: 0.0292\n",
      "Epoch 193/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0107 - val_loss: 0.0298\n",
      "Epoch 194/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0103 - val_loss: 0.0274\n",
      "Epoch 195/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0115 - val_loss: 0.0297\n",
      "Epoch 196/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0098 - val_loss: 0.0320\n",
      "Epoch 197/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0107 - val_loss: 0.0296\n",
      "Epoch 198/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0100 - val_loss: 0.0282\n",
      "Epoch 199/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0104 - val_loss: 0.0314\n",
      "Epoch 200/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0100 - val_loss: 0.0317\n",
      "Epoch 201/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0095 - val_loss: 0.0302\n",
      "Epoch 202/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0105 - val_loss: 0.0305\n",
      "Epoch 203/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0101 - val_loss: 0.0320\n",
      "Epoch 204/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0093 - val_loss: 0.0306\n",
      "Epoch 205/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0111 - val_loss: 0.0341\n",
      "Epoch 206/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0107 - val_loss: 0.0334\n",
      "Epoch 207/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0099 - val_loss: 0.0284\n",
      "Epoch 208/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0106 - val_loss: 0.0296\n",
      "Epoch 209/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0103 - val_loss: 0.0266\n",
      "Epoch 210/2000\n",
      "760/760 [==============================] - 0s 335us/step - loss: 0.0103 - val_loss: 0.0282\n",
      "Epoch 211/2000\n",
      "760/760 [==============================] - 0s 322us/step - loss: 0.0103 - val_loss: 0.0307\n",
      "Epoch 212/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0090 - val_loss: 0.0274\n",
      "Epoch 213/2000\n",
      "760/760 [==============================] - 0s 317us/step - loss: 0.0105 - val_loss: 0.0265\n",
      "Epoch 214/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0102 - val_loss: 0.0302\n",
      "Epoch 215/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0099 - val_loss: 0.0330\n",
      "Epoch 216/2000\n",
      "760/760 [==============================] - 0s 314us/step - loss: 0.0107 - val_loss: 0.0335\n",
      "Epoch 217/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0103 - val_loss: 0.0325\n",
      "Epoch 218/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0100 - val_loss: 0.0309\n",
      "Epoch 219/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0097 - val_loss: 0.0301\n",
      "Epoch 220/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0089 - val_loss: 0.0283\n",
      "Epoch 221/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0099 - val_loss: 0.0311\n",
      "Epoch 222/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0101 - val_loss: 0.0302\n",
      "Epoch 223/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0105 - val_loss: 0.0293\n",
      "Epoch 224/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0098 - val_loss: 0.0307\n",
      "Epoch 225/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0104 - val_loss: 0.0325\n",
      "Epoch 226/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0105 - val_loss: 0.0342\n",
      "Epoch 227/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0097 - val_loss: 0.0328\n",
      "Epoch 228/2000\n",
      "760/760 [==============================] - 0s 314us/step - loss: 0.0107 - val_loss: 0.0283\n",
      "Epoch 229/2000\n",
      "760/760 [==============================] - 0s 315us/step - loss: 0.0093 - val_loss: 0.0308\n",
      "Epoch 230/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0091 - val_loss: 0.0277\n",
      "Epoch 231/2000\n",
      "760/760 [==============================] - 0s 261us/step - loss: 0.0104 - val_loss: 0.0327\n",
      "Epoch 232/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0102 - val_loss: 0.0305\n",
      "Epoch 233/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0106 - val_loss: 0.0311\n",
      "Epoch 234/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0102 - val_loss: 0.0301\n",
      "Epoch 235/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0096 - val_loss: 0.0305\n",
      "Epoch 236/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0101 - val_loss: 0.0335\n",
      "Epoch 237/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0092 - val_loss: 0.0314\n",
      "Epoch 238/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0109 - val_loss: 0.0287\n",
      "Epoch 239/2000\n",
      "760/760 [==============================] - 0s 320us/step - loss: 0.0099 - val_loss: 0.0308\n",
      "Epoch 240/2000\n",
      "760/760 [==============================] - 0s 327us/step - loss: 0.0102 - val_loss: 0.0283\n",
      "Epoch 241/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0106 - val_loss: 0.0290\n",
      "Epoch 242/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0096 - val_loss: 0.0330\n",
      "Epoch 243/2000\n",
      "760/760 [==============================] - 0s 326us/step - loss: 0.0106 - val_loss: 0.0341\n",
      "Epoch 244/2000\n",
      "760/760 [==============================] - 0s 314us/step - loss: 0.0095 - val_loss: 0.0304\n",
      "Epoch 245/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0096 - val_loss: 0.0328\n",
      "Epoch 246/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0097 - val_loss: 0.0310\n",
      "Epoch 247/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0096 - val_loss: 0.0325\n",
      "Epoch 248/2000\n",
      "760/760 [==============================] - 0s 326us/step - loss: 0.0085 - val_loss: 0.0351\n",
      "Epoch 249/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0101 - val_loss: 0.0340\n",
      "Epoch 250/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0104 - val_loss: 0.0331\n",
      "Epoch 251/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0110 - val_loss: 0.0308\n",
      "Epoch 252/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0103 - val_loss: 0.0302\n",
      "Epoch 253/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0094 - val_loss: 0.0316\n",
      "Epoch 254/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0104 - val_loss: 0.0361\n",
      "Epoch 255/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0111 - val_loss: 0.0327\n",
      "Epoch 256/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0096 - val_loss: 0.0345\n",
      "Epoch 257/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0097 - val_loss: 0.0302\n",
      "Epoch 258/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0102 - val_loss: 0.0292\n",
      "Epoch 259/2000\n",
      "760/760 [==============================] - 0s 346us/step - loss: 0.0090 - val_loss: 0.0288\n",
      "Epoch 260/2000\n",
      "760/760 [==============================] - 0s 325us/step - loss: 0.0097 - val_loss: 0.0288\n",
      "Epoch 261/2000\n",
      "760/760 [==============================] - 0s 319us/step - loss: 0.0103 - val_loss: 0.0290\n",
      "Epoch 262/2000\n",
      "760/760 [==============================] - 0s 331us/step - loss: 0.0094 - val_loss: 0.0319\n",
      "Epoch 263/2000\n",
      "760/760 [==============================] - 0s 320us/step - loss: 0.0105 - val_loss: 0.0288\n",
      "Epoch 264/2000\n",
      "760/760 [==============================] - 0s 315us/step - loss: 0.0095 - val_loss: 0.0250\n",
      "Epoch 265/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0091 - val_loss: 0.0301\n",
      "Epoch 266/2000\n",
      "760/760 [==============================] - 0s 326us/step - loss: 0.0093 - val_loss: 0.0294\n",
      "Epoch 267/2000\n",
      "760/760 [==============================] - 0s 345us/step - loss: 0.0106 - val_loss: 0.0290\n",
      "Epoch 268/2000\n",
      "760/760 [==============================] - 0s 321us/step - loss: 0.0103 - val_loss: 0.0322\n",
      "Epoch 269/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0104 - val_loss: 0.0281\n",
      "Epoch 270/2000\n",
      "760/760 [==============================] - 0s 321us/step - loss: 0.0099 - val_loss: 0.0293\n",
      "Epoch 271/2000\n",
      "760/760 [==============================] - 0s 311us/step - loss: 0.0103 - val_loss: 0.0238\n",
      "Epoch 272/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0100 - val_loss: 0.0316\n",
      "Epoch 273/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0096 - val_loss: 0.0281\n",
      "Epoch 274/2000\n",
      "760/760 [==============================] - 0s 315us/step - loss: 0.0094 - val_loss: 0.0272\n",
      "Epoch 275/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0101 - val_loss: 0.0300\n",
      "Epoch 276/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0097 - val_loss: 0.0329\n",
      "Epoch 277/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0093 - val_loss: 0.0301\n",
      "Epoch 278/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0086 - val_loss: 0.0314\n",
      "Epoch 279/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0099 - val_loss: 0.0319\n",
      "Epoch 280/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0104 - val_loss: 0.0268\n",
      "Epoch 281/2000\n",
      "760/760 [==============================] - 0s 335us/step - loss: 0.0097 - val_loss: 0.0303\n",
      "Epoch 282/2000\n",
      "760/760 [==============================] - 0s 330us/step - loss: 0.0099 - val_loss: 0.0317\n",
      "Epoch 283/2000\n",
      "760/760 [==============================] - 0s 320us/step - loss: 0.0090 - val_loss: 0.0311\n",
      "Epoch 284/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0101 - val_loss: 0.0283\n",
      "Epoch 285/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0088 - val_loss: 0.0280\n",
      "Epoch 286/2000\n",
      "760/760 [==============================] - 0s 319us/step - loss: 0.0104 - val_loss: 0.0309\n",
      "Epoch 287/2000\n",
      "760/760 [==============================] - 0s 332us/step - loss: 0.0100 - val_loss: 0.0312\n",
      "Epoch 288/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0106 - val_loss: 0.0295\n",
      "Epoch 289/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0103 - val_loss: 0.0334\n",
      "Epoch 290/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0100 - val_loss: 0.0328\n",
      "Epoch 291/2000\n",
      "760/760 [==============================] - 0s 342us/step - loss: 0.0094 - val_loss: 0.0311\n",
      "Epoch 292/2000\n",
      "760/760 [==============================] - 0s 335us/step - loss: 0.0093 - val_loss: 0.0307\n",
      "Epoch 293/2000\n",
      "760/760 [==============================] - 0s 340us/step - loss: 0.0087 - val_loss: 0.0303\n",
      "Epoch 294/2000\n",
      "760/760 [==============================] - 0s 333us/step - loss: 0.0096 - val_loss: 0.0325\n",
      "Epoch 295/2000\n",
      "760/760 [==============================] - 0s 326us/step - loss: 0.0098 - val_loss: 0.0300\n",
      "Epoch 296/2000\n",
      "760/760 [==============================] - 0s 316us/step - loss: 0.0092 - val_loss: 0.0305\n",
      "Epoch 297/2000\n",
      "760/760 [==============================] - 0s 343us/step - loss: 0.0102 - val_loss: 0.0334\n",
      "Epoch 298/2000\n",
      "760/760 [==============================] - 0s 341us/step - loss: 0.0092 - val_loss: 0.0321\n",
      "Epoch 299/2000\n",
      "760/760 [==============================] - 0s 343us/step - loss: 0.0097 - val_loss: 0.0283\n",
      "Epoch 300/2000\n",
      "760/760 [==============================] - 0s 360us/step - loss: 0.0099 - val_loss: 0.0299\n",
      "Epoch 301/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0094 - val_loss: 0.0315\n",
      "Epoch 302/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0096 - val_loss: 0.0363\n",
      "Epoch 303/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0087 - val_loss: 0.0309\n",
      "Epoch 304/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0098 - val_loss: 0.0314\n",
      "Epoch 305/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0095 - val_loss: 0.0319\n",
      "Epoch 306/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0102 - val_loss: 0.0311\n",
      "Epoch 307/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0098 - val_loss: 0.0318\n",
      "Epoch 308/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0089 - val_loss: 0.0292\n",
      "Epoch 309/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 305us/step - loss: 0.0103 - val_loss: 0.0268\n",
      "Epoch 310/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0099 - val_loss: 0.0289\n",
      "Epoch 311/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0084 - val_loss: 0.0301\n",
      "Epoch 312/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0086 - val_loss: 0.0268\n",
      "Epoch 313/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0092 - val_loss: 0.0290\n",
      "Epoch 314/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0095 - val_loss: 0.0256\n",
      "Epoch 315/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0097 - val_loss: 0.0286\n",
      "Epoch 316/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0092 - val_loss: 0.0320\n",
      "Epoch 317/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0093 - val_loss: 0.0275\n",
      "Epoch 318/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0096 - val_loss: 0.0288\n",
      "Epoch 319/2000\n",
      "760/760 [==============================] - 0s 345us/step - loss: 0.0093 - val_loss: 0.0266\n",
      "Epoch 320/2000\n",
      "760/760 [==============================] - 0s 316us/step - loss: 0.0102 - val_loss: 0.0242\n",
      "Epoch 321/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0107 - val_loss: 0.0275\n",
      "Epoch 322/2000\n",
      "760/760 [==============================] - 0s 352us/step - loss: 0.0097 - val_loss: 0.0305\n",
      "Epoch 323/2000\n",
      "760/760 [==============================] - 0s 336us/step - loss: 0.0095 - val_loss: 0.0329\n",
      "Epoch 324/2000\n",
      "760/760 [==============================] - 0s 333us/step - loss: 0.0084 - val_loss: 0.0256\n",
      "Epoch 325/2000\n",
      "760/760 [==============================] - 0s 314us/step - loss: 0.0089 - val_loss: 0.0261\n",
      "Epoch 326/2000\n",
      "760/760 [==============================] - 0s 321us/step - loss: 0.0092 - val_loss: 0.0284\n",
      "Epoch 327/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0093 - val_loss: 0.0286\n",
      "Epoch 328/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0089 - val_loss: 0.0309\n",
      "Epoch 329/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0100 - val_loss: 0.0299\n",
      "Epoch 330/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0086 - val_loss: 0.0326\n",
      "Epoch 331/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0091 - val_loss: 0.0305\n",
      "Epoch 332/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0096 - val_loss: 0.0311\n",
      "Epoch 333/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0099 - val_loss: 0.0336\n",
      "Epoch 334/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0093 - val_loss: 0.0284\n",
      "Epoch 335/2000\n",
      "760/760 [==============================] - 0s 306us/step - loss: 0.0091 - val_loss: 0.0278\n",
      "Epoch 336/2000\n",
      "760/760 [==============================] - 0s 317us/step - loss: 0.0092 - val_loss: 0.0300\n",
      "Epoch 337/2000\n",
      "760/760 [==============================] - 0s 329us/step - loss: 0.0083 - val_loss: 0.0298\n",
      "Epoch 338/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0086 - val_loss: 0.0308\n",
      "Epoch 339/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0087 - val_loss: 0.0332\n",
      "Epoch 340/2000\n",
      "760/760 [==============================] - 0s 313us/step - loss: 0.0090 - val_loss: 0.0280\n",
      "Epoch 341/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0095 - val_loss: 0.0325\n",
      "Epoch 342/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0098 - val_loss: 0.0305\n",
      "Epoch 343/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0091 - val_loss: 0.0321\n",
      "Epoch 344/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0094 - val_loss: 0.0282\n",
      "Epoch 345/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0106 - val_loss: 0.0313\n",
      "Epoch 346/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0089 - val_loss: 0.0310\n",
      "Epoch 347/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0097 - val_loss: 0.0301\n",
      "Epoch 348/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0093 - val_loss: 0.0316\n",
      "Epoch 349/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0100 - val_loss: 0.0303\n",
      "Epoch 350/2000\n",
      "760/760 [==============================] - 0s 321us/step - loss: 0.0087 - val_loss: 0.0310\n",
      "Epoch 351/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0087 - val_loss: 0.0282\n",
      "Epoch 352/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0092 - val_loss: 0.0275\n",
      "Epoch 353/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0099 - val_loss: 0.0300\n",
      "Epoch 354/2000\n",
      "760/760 [==============================] - 0s 319us/step - loss: 0.0081 - val_loss: 0.0315\n",
      "Epoch 355/2000\n",
      "760/760 [==============================] - 0s 326us/step - loss: 0.0086 - val_loss: 0.0302\n",
      "Epoch 356/2000\n",
      "760/760 [==============================] - 0s 316us/step - loss: 0.0091 - val_loss: 0.0300\n",
      "Epoch 357/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0086 - val_loss: 0.0292\n",
      "Epoch 358/2000\n",
      "760/760 [==============================] - 0s 316us/step - loss: 0.0095 - val_loss: 0.0304\n",
      "Epoch 359/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0091 - val_loss: 0.0287\n",
      "Epoch 360/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0099 - val_loss: 0.0311\n",
      "Epoch 361/2000\n",
      "760/760 [==============================] - 0s 319us/step - loss: 0.0083 - val_loss: 0.0347\n",
      "Epoch 362/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0084 - val_loss: 0.0319\n",
      "Epoch 363/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0095 - val_loss: 0.0357\n",
      "Epoch 364/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0101 - val_loss: 0.0350\n",
      "Epoch 365/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0103 - val_loss: 0.0309\n",
      "Epoch 366/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0097 - val_loss: 0.0317\n",
      "Epoch 367/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0098 - val_loss: 0.0339\n",
      "Epoch 368/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0091 - val_loss: 0.0319\n",
      "Epoch 369/2000\n",
      "760/760 [==============================] - 0s 316us/step - loss: 0.0088 - val_loss: 0.0327\n",
      "Epoch 370/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0097 - val_loss: 0.0264\n",
      "Epoch 371/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0094 - val_loss: 0.0278\n",
      "Epoch 372/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0088 - val_loss: 0.0338\n",
      "Epoch 373/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0089 - val_loss: 0.0306\n",
      "Epoch 374/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0085 - val_loss: 0.0327\n",
      "Epoch 375/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0100 - val_loss: 0.0330\n",
      "Epoch 376/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0092 - val_loss: 0.0311\n",
      "Epoch 377/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0092 - val_loss: 0.0337\n",
      "Epoch 378/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0085 - val_loss: 0.0306\n",
      "Epoch 379/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0100 - val_loss: 0.0279\n",
      "Epoch 380/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0098 - val_loss: 0.0289\n",
      "Epoch 381/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0085 - val_loss: 0.0284\n",
      "Epoch 382/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0084 - val_loss: 0.0296\n",
      "Epoch 383/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0092 - val_loss: 0.0343\n",
      "Epoch 384/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0084 - val_loss: 0.0313\n",
      "Epoch 385/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0082 - val_loss: 0.0306\n",
      "Epoch 386/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0092 - val_loss: 0.0267\n",
      "Epoch 387/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0089 - val_loss: 0.0306\n",
      "Epoch 388/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0107 - val_loss: 0.0311\n",
      "Epoch 389/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0091 - val_loss: 0.0311\n",
      "Epoch 390/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0085 - val_loss: 0.0313\n",
      "Epoch 391/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0098 - val_loss: 0.0316\n",
      "Epoch 392/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0322\n",
      "Epoch 393/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0095 - val_loss: 0.0310\n",
      "Epoch 394/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0084 - val_loss: 0.0327\n",
      "Epoch 395/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0083 - val_loss: 0.0368\n",
      "Epoch 396/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0090 - val_loss: 0.0326\n",
      "Epoch 397/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0090 - val_loss: 0.0327\n",
      "Epoch 398/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0085 - val_loss: 0.0312\n",
      "Epoch 399/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0091 - val_loss: 0.0312\n",
      "Epoch 400/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0088 - val_loss: 0.0287\n",
      "Epoch 401/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0089 - val_loss: 0.0320\n",
      "Epoch 402/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0083 - val_loss: 0.0318\n",
      "Epoch 403/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0095 - val_loss: 0.0298\n",
      "Epoch 404/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0091 - val_loss: 0.0315\n",
      "Epoch 405/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0092 - val_loss: 0.0316\n",
      "Epoch 406/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0090 - val_loss: 0.0326\n",
      "Epoch 407/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0088 - val_loss: 0.0344\n",
      "Epoch 408/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0085 - val_loss: 0.0320\n",
      "Epoch 409/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0091 - val_loss: 0.0326\n",
      "Epoch 410/2000\n",
      "760/760 [==============================] - 0s 254us/step - loss: 0.0083 - val_loss: 0.0303\n",
      "Epoch 411/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0077 - val_loss: 0.0351\n",
      "Epoch 412/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0090 - val_loss: 0.0324\n",
      "Epoch 413/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0092 - val_loss: 0.0280\n",
      "Epoch 414/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0086 - val_loss: 0.0332\n",
      "Epoch 415/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0089 - val_loss: 0.0339\n",
      "Epoch 416/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0098 - val_loss: 0.0308\n",
      "Epoch 417/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0090 - val_loss: 0.0310\n",
      "Epoch 418/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0084 - val_loss: 0.0300\n",
      "Epoch 419/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0087 - val_loss: 0.0384\n",
      "Epoch 420/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0091 - val_loss: 0.0329\n",
      "Epoch 421/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0092 - val_loss: 0.0324\n",
      "Epoch 422/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0092 - val_loss: 0.0288\n",
      "Epoch 423/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0088 - val_loss: 0.0306\n",
      "Epoch 424/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0085 - val_loss: 0.0281\n",
      "Epoch 425/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0092 - val_loss: 0.0314\n",
      "Epoch 426/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0087 - val_loss: 0.0301\n",
      "Epoch 427/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0083 - val_loss: 0.0317\n",
      "Epoch 428/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0089 - val_loss: 0.0336\n",
      "Epoch 429/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0084 - val_loss: 0.0314\n",
      "Epoch 430/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0089 - val_loss: 0.0301\n",
      "Epoch 431/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0092 - val_loss: 0.0342\n",
      "Epoch 432/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0086 - val_loss: 0.0305\n",
      "Epoch 433/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0082 - val_loss: 0.0303\n",
      "Epoch 434/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0088 - val_loss: 0.0292\n",
      "Epoch 435/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0084 - val_loss: 0.0291\n",
      "Epoch 436/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0084 - val_loss: 0.0290\n",
      "Epoch 437/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0089 - val_loss: 0.0279\n",
      "Epoch 438/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0089 - val_loss: 0.0300\n",
      "Epoch 439/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0086 - val_loss: 0.0296\n",
      "Epoch 440/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0080 - val_loss: 0.0227\n",
      "Epoch 441/2000\n",
      "760/760 [==============================] - 0s 258us/step - loss: 0.0094 - val_loss: 0.0282\n",
      "Epoch 442/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0081 - val_loss: 0.0328\n",
      "Epoch 443/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0081 - val_loss: 0.0317\n",
      "Epoch 444/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0088 - val_loss: 0.0312\n",
      "Epoch 445/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0084 - val_loss: 0.0281\n",
      "Epoch 446/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0085 - val_loss: 0.0273\n",
      "Epoch 447/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0088 - val_loss: 0.0306\n",
      "Epoch 448/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0080 - val_loss: 0.0313\n",
      "Epoch 449/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0093 - val_loss: 0.0346\n",
      "Epoch 450/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0084 - val_loss: 0.0369\n",
      "Epoch 451/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0094 - val_loss: 0.0298\n",
      "Epoch 452/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0089 - val_loss: 0.0304\n",
      "Epoch 453/2000\n",
      "760/760 [==============================] - 0s 313us/step - loss: 0.0092 - val_loss: 0.0277\n",
      "Epoch 454/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0090 - val_loss: 0.0311\n",
      "Epoch 455/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0082 - val_loss: 0.0295\n",
      "Epoch 456/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0089 - val_loss: 0.0282\n",
      "Epoch 457/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0086 - val_loss: 0.0336\n",
      "Epoch 458/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0079 - val_loss: 0.0332\n",
      "Epoch 459/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0082 - val_loss: 0.0320\n",
      "Epoch 460/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0085 - val_loss: 0.0321\n",
      "Epoch 461/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0090 - val_loss: 0.0306\n",
      "Epoch 462/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0082 - val_loss: 0.0356\n",
      "Epoch 463/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 297us/step - loss: 0.0094 - val_loss: 0.0342\n",
      "Epoch 464/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0086 - val_loss: 0.0339\n",
      "Epoch 465/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0084 - val_loss: 0.0308\n",
      "Epoch 466/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0079 - val_loss: 0.0340\n",
      "Epoch 467/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0085 - val_loss: 0.0338\n",
      "Epoch 468/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0089 - val_loss: 0.0336\n",
      "Epoch 469/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0092 - val_loss: 0.0279\n",
      "Epoch 470/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0086 - val_loss: 0.0285\n",
      "Epoch 471/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0081 - val_loss: 0.0294\n",
      "Epoch 472/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0086 - val_loss: 0.0317\n",
      "Epoch 473/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0079 - val_loss: 0.0321\n",
      "Epoch 474/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0081 - val_loss: 0.0288\n",
      "Epoch 475/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0083 - val_loss: 0.0291\n",
      "Epoch 476/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0083 - val_loss: 0.0310\n",
      "Epoch 477/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0089 - val_loss: 0.0313\n",
      "Epoch 478/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0083 - val_loss: 0.0293\n",
      "Epoch 479/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0088 - val_loss: 0.0327\n",
      "Epoch 480/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0077 - val_loss: 0.0331\n",
      "Epoch 481/2000\n",
      "760/760 [==============================] - 0s 313us/step - loss: 0.0080 - val_loss: 0.0331\n",
      "Epoch 482/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0089 - val_loss: 0.0322\n",
      "Epoch 483/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0082 - val_loss: 0.0317\n",
      "Epoch 484/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0092 - val_loss: 0.0320\n",
      "Epoch 485/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0087 - val_loss: 0.0328\n",
      "Epoch 486/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0085 - val_loss: 0.0323\n",
      "Epoch 487/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0094 - val_loss: 0.0374\n",
      "Epoch 488/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0081 - val_loss: 0.0315\n",
      "Epoch 489/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0084 - val_loss: 0.0295\n",
      "Epoch 490/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0074 - val_loss: 0.0299\n",
      "Epoch 491/2000\n",
      "760/760 [==============================] - 0s 306us/step - loss: 0.0094 - val_loss: 0.0300\n",
      "Epoch 492/2000\n",
      "760/760 [==============================] - 0s 323us/step - loss: 0.0081 - val_loss: 0.0302\n",
      "Epoch 493/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0084 - val_loss: 0.0337\n",
      "Epoch 494/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0086 - val_loss: 0.0336\n",
      "Epoch 495/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0079 - val_loss: 0.0329\n",
      "Epoch 496/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0083 - val_loss: 0.0302\n",
      "Epoch 497/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0083 - val_loss: 0.0263\n",
      "Epoch 498/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0086 - val_loss: 0.0324\n",
      "Epoch 499/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0083 - val_loss: 0.0302\n",
      "Epoch 500/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0075 - val_loss: 0.0280\n",
      "Epoch 501/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0081 - val_loss: 0.0326\n",
      "Epoch 502/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0078 - val_loss: 0.0276\n",
      "Epoch 503/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0086 - val_loss: 0.0300\n",
      "Epoch 504/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0079 - val_loss: 0.0339\n",
      "Epoch 505/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0078 - val_loss: 0.0344\n",
      "Epoch 506/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0080 - val_loss: 0.0321\n",
      "Epoch 507/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0078 - val_loss: 0.0310\n",
      "Epoch 508/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0086 - val_loss: 0.0321\n",
      "Epoch 509/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0090 - val_loss: 0.0282\n",
      "Epoch 510/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0082 - val_loss: 0.0315\n",
      "Epoch 511/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0088 - val_loss: 0.0335\n",
      "Epoch 512/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0084 - val_loss: 0.0275\n",
      "Epoch 513/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0087 - val_loss: 0.0277\n",
      "Epoch 514/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0080 - val_loss: 0.0310\n",
      "Epoch 515/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0079 - val_loss: 0.0294\n",
      "Epoch 516/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0089 - val_loss: 0.0276\n",
      "Epoch 517/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0092 - val_loss: 0.0291\n",
      "Epoch 518/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0084 - val_loss: 0.0300\n",
      "Epoch 519/2000\n",
      "760/760 [==============================] - 0s 309us/step - loss: 0.0077 - val_loss: 0.0277\n",
      "Epoch 520/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0077 - val_loss: 0.0296\n",
      "Epoch 521/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0089 - val_loss: 0.0323\n",
      "Epoch 522/2000\n",
      "760/760 [==============================] - 0s 314us/step - loss: 0.0084 - val_loss: 0.0286\n",
      "Epoch 523/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0091 - val_loss: 0.0259\n",
      "Epoch 524/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0078 - val_loss: 0.0307\n",
      "Epoch 525/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0087 - val_loss: 0.0244\n",
      "Epoch 526/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0086 - val_loss: 0.0287\n",
      "Epoch 527/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0080 - val_loss: 0.0303\n",
      "Epoch 528/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0075 - val_loss: 0.0318\n",
      "Epoch 529/2000\n",
      "760/760 [==============================] - 0s 319us/step - loss: 0.0081 - val_loss: 0.0277\n",
      "Epoch 530/2000\n",
      "760/760 [==============================] - 0s 315us/step - loss: 0.0078 - val_loss: 0.0277\n",
      "Epoch 531/2000\n",
      "760/760 [==============================] - 0s 343us/step - loss: 0.0086 - val_loss: 0.0307\n",
      "Epoch 532/2000\n",
      "760/760 [==============================] - 0s 324us/step - loss: 0.0091 - val_loss: 0.0282\n",
      "Epoch 533/2000\n",
      "760/760 [==============================] - 0s 329us/step - loss: 0.0075 - val_loss: 0.0288\n",
      "Epoch 534/2000\n",
      "760/760 [==============================] - 0s 311us/step - loss: 0.0086 - val_loss: 0.0317\n",
      "Epoch 535/2000\n",
      "760/760 [==============================] - 0s 309us/step - loss: 0.0089 - val_loss: 0.0272\n",
      "Epoch 536/2000\n",
      "760/760 [==============================] - 0s 321us/step - loss: 0.0090 - val_loss: 0.0263\n",
      "Epoch 537/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0081 - val_loss: 0.0252\n",
      "Epoch 538/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0083 - val_loss: 0.0270\n",
      "Epoch 539/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0088 - val_loss: 0.0331\n",
      "Epoch 540/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0082 - val_loss: 0.0303\n",
      "Epoch 541/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0086 - val_loss: 0.0278\n",
      "Epoch 542/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0085 - val_loss: 0.0291\n",
      "Epoch 543/2000\n",
      "760/760 [==============================] - 0s 336us/step - loss: 0.0079 - val_loss: 0.0270\n",
      "Epoch 544/2000\n",
      "760/760 [==============================] - 0s 332us/step - loss: 0.0082 - val_loss: 0.0310\n",
      "Epoch 545/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0087 - val_loss: 0.0284\n",
      "Epoch 546/2000\n",
      "760/760 [==============================] - 0s 311us/step - loss: 0.0078 - val_loss: 0.0316\n",
      "Epoch 547/2000\n",
      "760/760 [==============================] - 0s 311us/step - loss: 0.0074 - val_loss: 0.0309\n",
      "Epoch 548/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0089 - val_loss: 0.0295\n",
      "Epoch 549/2000\n",
      "760/760 [==============================] - 0s 329us/step - loss: 0.0074 - val_loss: 0.0292\n",
      "Epoch 550/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0077 - val_loss: 0.0266\n",
      "Epoch 551/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0082 - val_loss: 0.0265\n",
      "Epoch 552/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0090 - val_loss: 0.0298\n",
      "Epoch 553/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0075 - val_loss: 0.0285\n",
      "Epoch 554/2000\n",
      "760/760 [==============================] - 0s 353us/step - loss: 0.0088 - val_loss: 0.0300\n",
      "Epoch 555/2000\n",
      "760/760 [==============================] - 0s 321us/step - loss: 0.0082 - val_loss: 0.0314\n",
      "Epoch 556/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0086 - val_loss: 0.0279\n",
      "Epoch 557/2000\n",
      "760/760 [==============================] - 0s 318us/step - loss: 0.0087 - val_loss: 0.0275\n",
      "Epoch 558/2000\n",
      "760/760 [==============================] - 0s 313us/step - loss: 0.0083 - val_loss: 0.0290\n",
      "Epoch 559/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0071 - val_loss: 0.0274\n",
      "Epoch 560/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0085 - val_loss: 0.0267\n",
      "Epoch 561/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0083 - val_loss: 0.0272\n",
      "Epoch 562/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0089 - val_loss: 0.0289\n",
      "Epoch 563/2000\n",
      "760/760 [==============================] - 0s 319us/step - loss: 0.0085 - val_loss: 0.0347\n",
      "Epoch 564/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0082 - val_loss: 0.0324\n",
      "Epoch 565/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0079 - val_loss: 0.0303\n",
      "Epoch 566/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0086 - val_loss: 0.0250\n",
      "Epoch 567/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0080 - val_loss: 0.0289\n",
      "Epoch 568/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0081 - val_loss: 0.0297\n",
      "Epoch 569/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0069 - val_loss: 0.0290\n",
      "Epoch 570/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0083 - val_loss: 0.0280\n",
      "Epoch 571/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0090 - val_loss: 0.0285\n",
      "Epoch 572/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0085 - val_loss: 0.0272\n",
      "Epoch 573/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0089 - val_loss: 0.0344\n",
      "Epoch 574/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0080 - val_loss: 0.0305\n",
      "Epoch 575/2000\n",
      "760/760 [==============================] - 0s 309us/step - loss: 0.0084 - val_loss: 0.0308\n",
      "Epoch 576/2000\n",
      "760/760 [==============================] - 0s 306us/step - loss: 0.0082 - val_loss: 0.0312\n",
      "Epoch 577/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0082 - val_loss: 0.0340\n",
      "Epoch 578/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0086 - val_loss: 0.0294\n",
      "Epoch 579/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0085 - val_loss: 0.0295\n",
      "Epoch 580/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0079 - val_loss: 0.0309\n",
      "Epoch 581/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0074 - val_loss: 0.0299\n",
      "Epoch 582/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0090 - val_loss: 0.0293\n",
      "Epoch 583/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0083 - val_loss: 0.0283\n",
      "Epoch 584/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0081 - val_loss: 0.0327\n",
      "Epoch 585/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0087 - val_loss: 0.0298\n",
      "Epoch 586/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0079 - val_loss: 0.0336\n",
      "Epoch 587/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0078 - val_loss: 0.0324\n",
      "Epoch 588/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0079 - val_loss: 0.0253\n",
      "Epoch 589/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0080 - val_loss: 0.0287\n",
      "Epoch 590/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0078 - val_loss: 0.0285\n",
      "Epoch 591/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0076 - val_loss: 0.0302\n",
      "Epoch 592/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0069 - val_loss: 0.0279\n",
      "Epoch 593/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0078 - val_loss: 0.0275\n",
      "Epoch 594/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0080 - val_loss: 0.0260\n",
      "Epoch 595/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0080 - val_loss: 0.0259\n",
      "Epoch 596/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0082 - val_loss: 0.0270\n",
      "Epoch 597/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0091 - val_loss: 0.0301\n",
      "Epoch 598/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0082 - val_loss: 0.0311\n",
      "Epoch 599/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0077 - val_loss: 0.0304\n",
      "Epoch 600/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0077 - val_loss: 0.0295\n",
      "Epoch 601/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0082 - val_loss: 0.0256\n",
      "Epoch 602/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0082 - val_loss: 0.0273\n",
      "Epoch 603/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0080 - val_loss: 0.0278\n",
      "Epoch 604/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0077 - val_loss: 0.0307\n",
      "Epoch 605/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0082 - val_loss: 0.0315\n",
      "Epoch 606/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0087 - val_loss: 0.0334\n",
      "Epoch 607/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0076 - val_loss: 0.0310\n",
      "Epoch 608/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0078 - val_loss: 0.0279\n",
      "Epoch 609/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0087 - val_loss: 0.0261\n",
      "Epoch 610/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0076 - val_loss: 0.0268\n",
      "Epoch 611/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0076 - val_loss: 0.0279\n",
      "Epoch 612/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0080 - val_loss: 0.0288\n",
      "Epoch 613/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0080 - val_loss: 0.0345\n",
      "Epoch 614/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0082 - val_loss: 0.0293\n",
      "Epoch 615/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0085 - val_loss: 0.0285\n",
      "Epoch 616/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0082 - val_loss: 0.0283\n",
      "Epoch 617/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 302us/step - loss: 0.0071 - val_loss: 0.0292\n",
      "Epoch 618/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0093 - val_loss: 0.0313\n",
      "Epoch 619/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0085 - val_loss: 0.0246\n",
      "Epoch 620/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0078 - val_loss: 0.0226\n",
      "Epoch 621/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0078 - val_loss: 0.0279\n",
      "Epoch 622/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0073 - val_loss: 0.0268\n",
      "Epoch 623/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0082 - val_loss: 0.0276\n",
      "Epoch 624/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0075 - val_loss: 0.0253\n",
      "Epoch 625/2000\n",
      "760/760 [==============================] - 0s 309us/step - loss: 0.0081 - val_loss: 0.0229\n",
      "Epoch 626/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0081 - val_loss: 0.0272\n",
      "Epoch 627/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0087 - val_loss: 0.0262\n",
      "Epoch 628/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0071 - val_loss: 0.0285\n",
      "Epoch 629/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0076 - val_loss: 0.0252\n",
      "Epoch 630/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0082 - val_loss: 0.0309\n",
      "Epoch 631/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0079 - val_loss: 0.0305\n",
      "Epoch 632/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0093 - val_loss: 0.0294\n",
      "Epoch 633/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0078 - val_loss: 0.0245\n",
      "Epoch 634/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0084 - val_loss: 0.0251\n",
      "Epoch 635/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0089 - val_loss: 0.0285\n",
      "Epoch 636/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0075 - val_loss: 0.0327\n",
      "Epoch 637/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0083 - val_loss: 0.0307\n",
      "Epoch 638/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0074 - val_loss: 0.0269\n",
      "Epoch 639/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0082 - val_loss: 0.0314\n",
      "Epoch 640/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0078 - val_loss: 0.0302\n",
      "Epoch 641/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0080 - val_loss: 0.0292\n",
      "Epoch 642/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0087 - val_loss: 0.0332\n",
      "Epoch 643/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0093 - val_loss: 0.0323\n",
      "Epoch 644/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0087 - val_loss: 0.0323\n",
      "Epoch 645/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0070 - val_loss: 0.0305\n",
      "Epoch 646/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0074 - val_loss: 0.0282\n",
      "Epoch 647/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0080 - val_loss: 0.0321\n",
      "Epoch 648/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0078 - val_loss: 0.0336\n",
      "Epoch 649/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0083 - val_loss: 0.0296\n",
      "Epoch 650/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0071 - val_loss: 0.0321\n",
      "Epoch 651/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0086 - val_loss: 0.0263\n",
      "Epoch 652/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0079 - val_loss: 0.0278\n",
      "Epoch 653/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0078 - val_loss: 0.0279\n",
      "Epoch 654/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0071 - val_loss: 0.0292\n",
      "Epoch 655/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0083 - val_loss: 0.0317\n",
      "Epoch 656/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0081 - val_loss: 0.0278\n",
      "Epoch 657/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0066 - val_loss: 0.0277\n",
      "Epoch 658/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0074 - val_loss: 0.0310\n",
      "Epoch 659/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0075 - val_loss: 0.0294\n",
      "Epoch 660/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0082 - val_loss: 0.0263\n",
      "Epoch 661/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0076 - val_loss: 0.0263\n",
      "Epoch 662/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0082 - val_loss: 0.0321\n",
      "Epoch 663/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0081 - val_loss: 0.0306\n",
      "Epoch 664/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0085 - val_loss: 0.0328\n",
      "Epoch 665/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0082 - val_loss: 0.0321\n",
      "Epoch 666/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0080 - val_loss: 0.0336\n",
      "Epoch 667/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0091 - val_loss: 0.0307\n",
      "Epoch 668/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0083 - val_loss: 0.0276\n",
      "Epoch 669/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0075 - val_loss: 0.0302\n",
      "Epoch 670/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0083 - val_loss: 0.0306\n",
      "Epoch 671/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0082 - val_loss: 0.0292\n",
      "Epoch 672/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0078 - val_loss: 0.0290\n",
      "Epoch 673/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0075 - val_loss: 0.0293\n",
      "Epoch 674/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0078 - val_loss: 0.0326\n",
      "Epoch 675/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0074 - val_loss: 0.0277\n",
      "Epoch 676/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0082 - val_loss: 0.0259\n",
      "Epoch 677/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0083 - val_loss: 0.0247\n",
      "Epoch 678/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0080 - val_loss: 0.0262\n",
      "Epoch 679/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0074 - val_loss: 0.0296\n",
      "Epoch 680/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0079 - val_loss: 0.0305\n",
      "Epoch 681/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0084 - val_loss: 0.0311\n",
      "Epoch 682/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0079 - val_loss: 0.0300\n",
      "Epoch 683/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0079 - val_loss: 0.0295\n",
      "Epoch 684/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0070 - val_loss: 0.0284\n",
      "Epoch 685/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0071 - val_loss: 0.0233\n",
      "Epoch 686/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0087 - val_loss: 0.0322\n",
      "Epoch 687/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0083 - val_loss: 0.0301\n",
      "Epoch 688/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0079 - val_loss: 0.0277\n",
      "Epoch 689/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0079 - val_loss: 0.0279\n",
      "Epoch 690/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0076 - val_loss: 0.0341\n",
      "Epoch 691/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0085 - val_loss: 0.0364\n",
      "Epoch 692/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0080 - val_loss: 0.0316\n",
      "Epoch 693/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0077 - val_loss: 0.0336\n",
      "Epoch 694/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0076 - val_loss: 0.0333\n",
      "Epoch 695/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0081 - val_loss: 0.0292\n",
      "Epoch 696/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0079 - val_loss: 0.0280\n",
      "Epoch 697/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0079 - val_loss: 0.0306\n",
      "Epoch 698/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0087 - val_loss: 0.0263\n",
      "Epoch 699/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0075 - val_loss: 0.0266\n",
      "Epoch 700/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0079 - val_loss: 0.0305\n",
      "Epoch 701/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0075 - val_loss: 0.0336\n",
      "Epoch 702/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0078 - val_loss: 0.0262\n",
      "Epoch 703/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0083 - val_loss: 0.0311\n",
      "Epoch 704/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0084 - val_loss: 0.0282\n",
      "Epoch 705/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0078 - val_loss: 0.0268\n",
      "Epoch 706/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0076 - val_loss: 0.0247\n",
      "Epoch 707/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0084 - val_loss: 0.0257\n",
      "Epoch 708/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0076 - val_loss: 0.0295\n",
      "Epoch 709/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0075 - val_loss: 0.0269\n",
      "Epoch 710/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0082 - val_loss: 0.0244\n",
      "Epoch 711/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0078 - val_loss: 0.0250\n",
      "Epoch 712/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0075 - val_loss: 0.0276\n",
      "Epoch 713/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0087 - val_loss: 0.0271\n",
      "Epoch 714/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0075 - val_loss: 0.0279\n",
      "Epoch 715/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0084 - val_loss: 0.0259\n",
      "Epoch 716/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0075 - val_loss: 0.0279\n",
      "Epoch 717/2000\n",
      "760/760 [==============================] - 0s 306us/step - loss: 0.0074 - val_loss: 0.0295\n",
      "Epoch 718/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0081 - val_loss: 0.0251\n",
      "Epoch 719/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0080 - val_loss: 0.0273\n",
      "Epoch 720/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0074 - val_loss: 0.0248\n",
      "Epoch 721/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0091 - val_loss: 0.0281\n",
      "Epoch 722/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0069 - val_loss: 0.0313\n",
      "Epoch 723/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0079 - val_loss: 0.0293\n",
      "Epoch 724/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0075 - val_loss: 0.0276\n",
      "Epoch 725/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0078 - val_loss: 0.0252\n",
      "Epoch 726/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0077 - val_loss: 0.0272\n",
      "Epoch 727/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0077 - val_loss: 0.0309\n",
      "Epoch 728/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0077 - val_loss: 0.0284\n",
      "Epoch 729/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0079 - val_loss: 0.0274\n",
      "Epoch 730/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0076 - val_loss: 0.0242\n",
      "Epoch 731/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0081 - val_loss: 0.0274\n",
      "Epoch 732/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0085 - val_loss: 0.0241\n",
      "Epoch 733/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0083 - val_loss: 0.0321\n",
      "Epoch 734/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0077 - val_loss: 0.0250\n",
      "Epoch 735/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0068 - val_loss: 0.0313\n",
      "Epoch 736/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0078 - val_loss: 0.0256\n",
      "Epoch 737/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0068 - val_loss: 0.0310\n",
      "Epoch 738/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0073 - val_loss: 0.0271\n",
      "Epoch 739/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0074 - val_loss: 0.0233\n",
      "Epoch 740/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0088 - val_loss: 0.0220\n",
      "Epoch 741/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0077 - val_loss: 0.0234\n",
      "Epoch 742/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0080 - val_loss: 0.0275\n",
      "Epoch 743/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0082 - val_loss: 0.0265\n",
      "Epoch 744/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0075 - val_loss: 0.0262\n",
      "Epoch 745/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0074 - val_loss: 0.0280\n",
      "Epoch 746/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0077 - val_loss: 0.0266\n",
      "Epoch 747/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0074 - val_loss: 0.0281\n",
      "Epoch 748/2000\n",
      "760/760 [==============================] - 0s 263us/step - loss: 0.0079 - val_loss: 0.0243\n",
      "Epoch 749/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0088 - val_loss: 0.0271\n",
      "Epoch 750/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0079 - val_loss: 0.0303\n",
      "Epoch 751/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0072 - val_loss: 0.0276\n",
      "Epoch 752/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0082 - val_loss: 0.0247\n",
      "Epoch 753/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0080 - val_loss: 0.0301\n",
      "Epoch 754/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0075 - val_loss: 0.0302\n",
      "Epoch 755/2000\n",
      "760/760 [==============================] - 0s 318us/step - loss: 0.0080 - val_loss: 0.0283\n",
      "Epoch 756/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0084 - val_loss: 0.0302\n",
      "Epoch 757/2000\n",
      "760/760 [==============================] - 0s 318us/step - loss: 0.0077 - val_loss: 0.0315\n",
      "Epoch 758/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0070 - val_loss: 0.0282\n",
      "Epoch 759/2000\n",
      "760/760 [==============================] - 0s 318us/step - loss: 0.0075 - val_loss: 0.0258\n",
      "Epoch 760/2000\n",
      "760/760 [==============================] - 0s 318us/step - loss: 0.0083 - val_loss: 0.0285\n",
      "Epoch 761/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0079 - val_loss: 0.0258\n",
      "Epoch 762/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0086 - val_loss: 0.0277\n",
      "Epoch 763/2000\n",
      "760/760 [==============================] - 0s 329us/step - loss: 0.0080 - val_loss: 0.0242\n",
      "Epoch 764/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0078 - val_loss: 0.0231\n",
      "Epoch 765/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0079 - val_loss: 0.0258\n",
      "Epoch 766/2000\n",
      "760/760 [==============================] - 0s 256us/step - loss: 0.0072 - val_loss: 0.0296\n",
      "Epoch 767/2000\n",
      "760/760 [==============================] - 0s 253us/step - loss: 0.0078 - val_loss: 0.0262\n",
      "Epoch 768/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0079 - val_loss: 0.0298\n",
      "Epoch 769/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0080 - val_loss: 0.0318\n",
      "Epoch 770/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0087 - val_loss: 0.0300\n",
      "Epoch 771/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 283us/step - loss: 0.0075 - val_loss: 0.0291\n",
      "Epoch 772/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0081 - val_loss: 0.0322\n",
      "Epoch 773/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0082 - val_loss: 0.0306\n",
      "Epoch 774/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0080 - val_loss: 0.0294\n",
      "Epoch 775/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0081 - val_loss: 0.0268\n",
      "Epoch 776/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0076 - val_loss: 0.0257\n",
      "Epoch 777/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0078 - val_loss: 0.0258\n",
      "Epoch 778/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0073 - val_loss: 0.0290\n",
      "Epoch 779/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0073 - val_loss: 0.0248\n",
      "Epoch 780/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0080 - val_loss: 0.0246\n",
      "Epoch 781/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0073 - val_loss: 0.0274\n",
      "Epoch 782/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0076 - val_loss: 0.0296\n",
      "Epoch 783/2000\n",
      "760/760 [==============================] - 0s 340us/step - loss: 0.0081 - val_loss: 0.0301\n",
      "Epoch 784/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0078 - val_loss: 0.0312\n",
      "Epoch 785/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0084 - val_loss: 0.0277\n",
      "Epoch 786/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0085 - val_loss: 0.0276\n",
      "Epoch 787/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0080 - val_loss: 0.0246\n",
      "Epoch 788/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0084 - val_loss: 0.0269\n",
      "Epoch 789/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0079 - val_loss: 0.0302\n",
      "Epoch 790/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0076 - val_loss: 0.0311\n",
      "Epoch 791/2000\n",
      "760/760 [==============================] - 0s 313us/step - loss: 0.0081 - val_loss: 0.0299\n",
      "Epoch 792/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0075 - val_loss: 0.0256\n",
      "Epoch 793/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0076 - val_loss: 0.0248\n",
      "Epoch 794/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0078 - val_loss: 0.0267\n",
      "Epoch 795/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0069 - val_loss: 0.0300\n",
      "Epoch 796/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0068 - val_loss: 0.0294\n",
      "Epoch 797/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0077 - val_loss: 0.0270\n",
      "Epoch 798/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0084 - val_loss: 0.0275\n",
      "Epoch 799/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0078 - val_loss: 0.0289\n",
      "Epoch 800/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0076 - val_loss: 0.0293\n",
      "Epoch 801/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0075 - val_loss: 0.0285\n",
      "Epoch 802/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0075 - val_loss: 0.0282\n",
      "Epoch 803/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0079 - val_loss: 0.0239\n",
      "Epoch 804/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0076 - val_loss: 0.0277\n",
      "Epoch 805/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0068 - val_loss: 0.0294\n",
      "Epoch 806/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0071 - val_loss: 0.0251\n",
      "Epoch 807/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0084 - val_loss: 0.0271\n",
      "Epoch 808/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0074 - val_loss: 0.0269\n",
      "Epoch 809/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0083 - val_loss: 0.0308\n",
      "Epoch 810/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0077 - val_loss: 0.0285\n",
      "Epoch 811/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0075 - val_loss: 0.0273\n",
      "Epoch 812/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0062 - val_loss: 0.0307\n",
      "Epoch 813/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0079 - val_loss: 0.0275\n",
      "Epoch 814/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0072 - val_loss: 0.0283\n",
      "Epoch 815/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0075 - val_loss: 0.0299\n",
      "Epoch 816/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0074 - val_loss: 0.0293\n",
      "Epoch 817/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0082 - val_loss: 0.0301\n",
      "Epoch 818/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0080 - val_loss: 0.0256\n",
      "Epoch 819/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0077 - val_loss: 0.0353\n",
      "Epoch 820/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0080 - val_loss: 0.0296\n",
      "Epoch 821/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0079 - val_loss: 0.0282\n",
      "Epoch 822/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0079 - val_loss: 0.0274\n",
      "Epoch 823/2000\n",
      "760/760 [==============================] - 0s 306us/step - loss: 0.0072 - val_loss: 0.0278\n",
      "Epoch 824/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0075 - val_loss: 0.0286\n",
      "Epoch 825/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0077 - val_loss: 0.0277\n",
      "Epoch 826/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0071 - val_loss: 0.0279\n",
      "Epoch 827/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0074 - val_loss: 0.0266\n",
      "Epoch 828/2000\n",
      "760/760 [==============================] - 0s 261us/step - loss: 0.0071 - val_loss: 0.0282\n",
      "Epoch 829/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0070 - val_loss: 0.0296\n",
      "Epoch 830/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0081 - val_loss: 0.0247\n",
      "Epoch 831/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0082 - val_loss: 0.0269\n",
      "Epoch 832/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0081 - val_loss: 0.0266\n",
      "Epoch 833/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0074 - val_loss: 0.0250\n",
      "Epoch 834/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0085 - val_loss: 0.0217\n",
      "Epoch 835/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0077 - val_loss: 0.0257\n",
      "Epoch 836/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0075 - val_loss: 0.0263\n",
      "Epoch 837/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0081 - val_loss: 0.0278\n",
      "Epoch 838/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0081 - val_loss: 0.0256\n",
      "Epoch 839/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0079 - val_loss: 0.0270\n",
      "Epoch 840/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0079 - val_loss: 0.0260\n",
      "Epoch 841/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0078 - val_loss: 0.0292\n",
      "Epoch 842/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0078 - val_loss: 0.0261\n",
      "Epoch 843/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0080 - val_loss: 0.0241\n",
      "Epoch 844/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0076 - val_loss: 0.0277\n",
      "Epoch 845/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0082 - val_loss: 0.0279\n",
      "Epoch 846/2000\n",
      "760/760 [==============================] - 0s 309us/step - loss: 0.0074 - val_loss: 0.0305\n",
      "Epoch 847/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0084 - val_loss: 0.0251\n",
      "Epoch 848/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0080 - val_loss: 0.0272\n",
      "Epoch 849/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0079 - val_loss: 0.0284\n",
      "Epoch 850/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0081 - val_loss: 0.0257\n",
      "Epoch 851/2000\n",
      "760/760 [==============================] - 0s 313us/step - loss: 0.0074 - val_loss: 0.0282\n",
      "Epoch 852/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0069 - val_loss: 0.0312\n",
      "Epoch 853/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0079 - val_loss: 0.0281\n",
      "Epoch 854/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0078 - val_loss: 0.0327\n",
      "Epoch 855/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0077 - val_loss: 0.0299\n",
      "Epoch 856/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0082 - val_loss: 0.0257\n",
      "Epoch 857/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0083 - val_loss: 0.0253\n",
      "Epoch 858/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0075 - val_loss: 0.0257\n",
      "Epoch 859/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0081 - val_loss: 0.0283\n",
      "Epoch 860/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0074 - val_loss: 0.0297\n",
      "Epoch 861/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0077 - val_loss: 0.0289\n",
      "Epoch 862/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0077 - val_loss: 0.0268\n",
      "Epoch 863/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0082 - val_loss: 0.0271\n",
      "Epoch 864/2000\n",
      "760/760 [==============================] - 0s 310us/step - loss: 0.0072 - val_loss: 0.0291\n",
      "Epoch 865/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0079 - val_loss: 0.0280\n",
      "Epoch 866/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0080 - val_loss: 0.0239\n",
      "Epoch 867/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0073 - val_loss: 0.0263\n",
      "Epoch 868/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0083 - val_loss: 0.0274\n",
      "Epoch 869/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0074 - val_loss: 0.0287\n",
      "Epoch 870/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0071 - val_loss: 0.0270\n",
      "Epoch 871/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0257\n",
      "Epoch 872/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0072 - val_loss: 0.0263\n",
      "Epoch 873/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0079 - val_loss: 0.0281\n",
      "Epoch 874/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0067 - val_loss: 0.0313\n",
      "Epoch 875/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0067 - val_loss: 0.0309\n",
      "Epoch 876/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0080 - val_loss: 0.0306\n",
      "Epoch 877/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0075 - val_loss: 0.0318\n",
      "Epoch 878/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0070 - val_loss: 0.0299\n",
      "Epoch 879/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0079 - val_loss: 0.0307\n",
      "Epoch 880/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0080 - val_loss: 0.0291\n",
      "Epoch 881/2000\n",
      "760/760 [==============================] - 0s 260us/step - loss: 0.0080 - val_loss: 0.0279\n",
      "Epoch 882/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0078 - val_loss: 0.0263\n",
      "Epoch 883/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0075 - val_loss: 0.0277\n",
      "Epoch 884/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0080 - val_loss: 0.0263\n",
      "Epoch 885/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0081 - val_loss: 0.0313\n",
      "Epoch 886/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0076 - val_loss: 0.0288\n",
      "Epoch 887/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0070 - val_loss: 0.0266\n",
      "Epoch 888/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0079 - val_loss: 0.0247\n",
      "Epoch 889/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0074 - val_loss: 0.0246\n",
      "Epoch 890/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0073 - val_loss: 0.0267\n",
      "Epoch 891/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0079 - val_loss: 0.0275\n",
      "Epoch 892/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0083 - val_loss: 0.0291\n",
      "Epoch 893/2000\n",
      "760/760 [==============================] - 0s 325us/step - loss: 0.0073 - val_loss: 0.0270\n",
      "Epoch 894/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0069 - val_loss: 0.0308\n",
      "Epoch 895/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0072 - val_loss: 0.0311\n",
      "Epoch 896/2000\n",
      "760/760 [==============================] - 0s 315us/step - loss: 0.0073 - val_loss: 0.0286\n",
      "Epoch 897/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0080 - val_loss: 0.0303\n",
      "Epoch 898/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0076 - val_loss: 0.0281\n",
      "Epoch 899/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0078 - val_loss: 0.0303\n",
      "Epoch 900/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0071 - val_loss: 0.0290\n",
      "Epoch 901/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0076 - val_loss: 0.0236\n",
      "Epoch 902/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0081 - val_loss: 0.0231\n",
      "Epoch 903/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0069 - val_loss: 0.0256\n",
      "Epoch 904/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0080 - val_loss: 0.0319\n",
      "Epoch 905/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0077 - val_loss: 0.0280\n",
      "Epoch 906/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0071 - val_loss: 0.0289\n",
      "Epoch 907/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0081 - val_loss: 0.0286\n",
      "Epoch 908/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0083 - val_loss: 0.0308\n",
      "Epoch 909/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0068 - val_loss: 0.0294\n",
      "Epoch 910/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0077 - val_loss: 0.0268\n",
      "Epoch 911/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0069 - val_loss: 0.0245\n",
      "Epoch 912/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0086 - val_loss: 0.0267\n",
      "Epoch 913/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0076 - val_loss: 0.0259\n",
      "Epoch 914/2000\n",
      "760/760 [==============================] - 0s 312us/step - loss: 0.0077 - val_loss: 0.0248\n",
      "Epoch 915/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0068 - val_loss: 0.0235\n",
      "Epoch 916/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0073 - val_loss: 0.0283\n",
      "Epoch 917/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0076 - val_loss: 0.0281\n",
      "Epoch 918/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0076 - val_loss: 0.0275\n",
      "Epoch 919/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0086 - val_loss: 0.0293\n",
      "Epoch 920/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0084 - val_loss: 0.0320\n",
      "Epoch 921/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0075 - val_loss: 0.0275\n",
      "Epoch 922/2000\n",
      "760/760 [==============================] - 0s 255us/step - loss: 0.0076 - val_loss: 0.0268\n",
      "Epoch 923/2000\n",
      "760/760 [==============================] - 0s 255us/step - loss: 0.0085 - val_loss: 0.0302\n",
      "Epoch 924/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0072 - val_loss: 0.0278\n",
      "Epoch 925/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 274us/step - loss: 0.0082 - val_loss: 0.0312\n",
      "Epoch 926/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0073 - val_loss: 0.0277\n",
      "Epoch 927/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0070 - val_loss: 0.0270\n",
      "Epoch 928/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0074 - val_loss: 0.0270\n",
      "Epoch 929/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0078 - val_loss: 0.0274\n",
      "Epoch 930/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0080 - val_loss: 0.0308\n",
      "Epoch 931/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0078 - val_loss: 0.0302\n",
      "Epoch 932/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0078 - val_loss: 0.0311\n",
      "Epoch 933/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0069 - val_loss: 0.0315\n",
      "Epoch 934/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0065 - val_loss: 0.0300\n",
      "Epoch 935/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0068 - val_loss: 0.0320\n",
      "Epoch 936/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0077 - val_loss: 0.0317\n",
      "Epoch 937/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0076 - val_loss: 0.0271\n",
      "Epoch 938/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0073 - val_loss: 0.0275\n",
      "Epoch 939/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0073 - val_loss: 0.0248\n",
      "Epoch 940/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0074 - val_loss: 0.0283\n",
      "Epoch 941/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0085 - val_loss: 0.0212\n",
      "Epoch 942/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0078 - val_loss: 0.0237\n",
      "Epoch 943/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0078 - val_loss: 0.0234\n",
      "Epoch 944/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0068 - val_loss: 0.0289\n",
      "Epoch 945/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0064 - val_loss: 0.0289\n",
      "Epoch 946/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0076 - val_loss: 0.0276\n",
      "Epoch 947/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0082 - val_loss: 0.0234\n",
      "Epoch 948/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0077 - val_loss: 0.0290\n",
      "Epoch 949/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0072 - val_loss: 0.0306\n",
      "Epoch 950/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0070 - val_loss: 0.0288\n",
      "Epoch 951/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0281\n",
      "Epoch 952/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0077 - val_loss: 0.0290\n",
      "Epoch 953/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0078 - val_loss: 0.0291\n",
      "Epoch 954/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0074 - val_loss: 0.0279\n",
      "Epoch 955/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0071 - val_loss: 0.0294\n",
      "Epoch 956/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0072 - val_loss: 0.0275\n",
      "Epoch 957/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0296\n",
      "Epoch 958/2000\n",
      "760/760 [==============================] - 0s 259us/step - loss: 0.0071 - val_loss: 0.0320\n",
      "Epoch 959/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0068 - val_loss: 0.0281\n",
      "Epoch 960/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0067 - val_loss: 0.0316\n",
      "Epoch 961/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0073 - val_loss: 0.0323\n",
      "Epoch 962/2000\n",
      "760/760 [==============================] - 0s 315us/step - loss: 0.0069 - val_loss: 0.0274\n",
      "Epoch 963/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0074 - val_loss: 0.0298\n",
      "Epoch 964/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0067 - val_loss: 0.0300\n",
      "Epoch 965/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0080 - val_loss: 0.0306\n",
      "Epoch 966/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0071 - val_loss: 0.0321\n",
      "Epoch 967/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0075 - val_loss: 0.0308\n",
      "Epoch 968/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0067 - val_loss: 0.0301\n",
      "Epoch 969/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0076 - val_loss: 0.0266\n",
      "Epoch 970/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0070 - val_loss: 0.0299\n",
      "Epoch 971/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0060 - val_loss: 0.0295\n",
      "Epoch 972/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0078 - val_loss: 0.0289\n",
      "Epoch 973/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0076 - val_loss: 0.0356\n",
      "Epoch 974/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0073 - val_loss: 0.0337\n",
      "Epoch 975/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0073 - val_loss: 0.0273\n",
      "Epoch 976/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0083 - val_loss: 0.0271\n",
      "Epoch 977/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0066 - val_loss: 0.0277\n",
      "Epoch 978/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0065 - val_loss: 0.0278\n",
      "Epoch 979/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0072 - val_loss: 0.0292\n",
      "Epoch 980/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0068 - val_loss: 0.0289\n",
      "Epoch 981/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0079 - val_loss: 0.0293\n",
      "Epoch 982/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0073 - val_loss: 0.0264\n",
      "Epoch 983/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0069 - val_loss: 0.0313\n",
      "Epoch 984/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0065 - val_loss: 0.0266\n",
      "Epoch 985/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0078 - val_loss: 0.0273\n",
      "Epoch 986/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0076 - val_loss: 0.0266\n",
      "Epoch 987/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0072 - val_loss: 0.0299\n",
      "Epoch 988/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0072 - val_loss: 0.0294\n",
      "Epoch 989/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0075 - val_loss: 0.0267\n",
      "Epoch 990/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0073 - val_loss: 0.0331\n",
      "Epoch 991/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0075 - val_loss: 0.0311\n",
      "Epoch 992/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0079 - val_loss: 0.0316\n",
      "Epoch 993/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0076 - val_loss: 0.0226\n",
      "Epoch 994/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0079 - val_loss: 0.0291\n",
      "Epoch 995/2000\n",
      "760/760 [==============================] - 0s 260us/step - loss: 0.0072 - val_loss: 0.0287\n",
      "Epoch 996/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0067 - val_loss: 0.0267\n",
      "Epoch 997/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0081 - val_loss: 0.0303\n",
      "Epoch 998/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0073 - val_loss: 0.0290\n",
      "Epoch 999/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0068 - val_loss: 0.0318\n",
      "Epoch 1000/2000\n",
      "760/760 [==============================] - 0s 261us/step - loss: 0.0069 - val_loss: 0.0311\n",
      "Epoch 1001/2000\n",
      "760/760 [==============================] - 0s 244us/step - loss: 0.0074 - val_loss: 0.0311\n",
      "Epoch 1002/2000\n",
      "760/760 [==============================] - 0s 254us/step - loss: 0.0075 - val_loss: 0.0285\n",
      "Epoch 1003/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0081 - val_loss: 0.0298\n",
      "Epoch 1004/2000\n",
      "760/760 [==============================] - 0s 256us/step - loss: 0.0085 - val_loss: 0.0284\n",
      "Epoch 1005/2000\n",
      "760/760 [==============================] - 0s 255us/step - loss: 0.0067 - val_loss: 0.0299\n",
      "Epoch 1006/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0079 - val_loss: 0.0310\n",
      "Epoch 1007/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0075 - val_loss: 0.0305\n",
      "Epoch 1008/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0070 - val_loss: 0.0302\n",
      "Epoch 1009/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0076 - val_loss: 0.0287\n",
      "Epoch 1010/2000\n",
      "760/760 [==============================] - 0s 248us/step - loss: 0.0076 - val_loss: 0.0320\n",
      "Epoch 1011/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0073 - val_loss: 0.0285\n",
      "Epoch 1012/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0089 - val_loss: 0.0248\n",
      "Epoch 1013/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0069 - val_loss: 0.0291\n",
      "Epoch 1014/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0081 - val_loss: 0.0236\n",
      "Epoch 1015/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0067 - val_loss: 0.0296\n",
      "Epoch 1016/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0075 - val_loss: 0.0321\n",
      "Epoch 1017/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0080 - val_loss: 0.0297\n",
      "Epoch 1018/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0079 - val_loss: 0.0263\n",
      "Epoch 1019/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0089 - val_loss: 0.0292\n",
      "Epoch 1020/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0070 - val_loss: 0.0287\n",
      "Epoch 1021/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0070 - val_loss: 0.0283\n",
      "Epoch 1022/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0075 - val_loss: 0.0263\n",
      "Epoch 1023/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0077 - val_loss: 0.0299\n",
      "Epoch 1024/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0075 - val_loss: 0.0255\n",
      "Epoch 1025/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0078 - val_loss: 0.0311\n",
      "Epoch 1026/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0075 - val_loss: 0.0308\n",
      "Epoch 1027/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0080 - val_loss: 0.0288\n",
      "Epoch 1028/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0072 - val_loss: 0.0247\n",
      "Epoch 1029/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0075 - val_loss: 0.0268\n",
      "Epoch 1030/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0078 - val_loss: 0.0292\n",
      "Epoch 1031/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0078 - val_loss: 0.0282\n",
      "Epoch 1032/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0076 - val_loss: 0.0286\n",
      "Epoch 1033/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0071 - val_loss: 0.0274\n",
      "Epoch 1034/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0069 - val_loss: 0.0282\n",
      "Epoch 1035/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0066 - val_loss: 0.0268\n",
      "Epoch 1036/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0070 - val_loss: 0.0253\n",
      "Epoch 1037/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0076 - val_loss: 0.0247\n",
      "Epoch 1038/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0070 - val_loss: 0.0290\n",
      "Epoch 1039/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0070 - val_loss: 0.0256\n",
      "Epoch 1040/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0083 - val_loss: 0.0277\n",
      "Epoch 1041/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0075 - val_loss: 0.0304\n",
      "Epoch 1042/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0076 - val_loss: 0.0278\n",
      "Epoch 1043/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0080 - val_loss: 0.0244\n",
      "Epoch 1044/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0080 - val_loss: 0.0286\n",
      "Epoch 1045/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0287\n",
      "Epoch 1046/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0066 - val_loss: 0.0300\n",
      "Epoch 1047/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0076 - val_loss: 0.0282\n",
      "Epoch 1048/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0072 - val_loss: 0.0252\n",
      "Epoch 1049/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0064 - val_loss: 0.0235\n",
      "Epoch 1050/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0081 - val_loss: 0.0272\n",
      "Epoch 1051/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0077 - val_loss: 0.0269\n",
      "Epoch 1052/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0067 - val_loss: 0.0334\n",
      "Epoch 1053/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0074 - val_loss: 0.0316\n",
      "Epoch 1054/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0079 - val_loss: 0.0268\n",
      "Epoch 1055/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0070 - val_loss: 0.0299\n",
      "Epoch 1056/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0062 - val_loss: 0.0274\n",
      "Epoch 1057/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0074 - val_loss: 0.0266\n",
      "Epoch 1058/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0071 - val_loss: 0.0258\n",
      "Epoch 1059/2000\n",
      "760/760 [==============================] - 0s 309us/step - loss: 0.0080 - val_loss: 0.0260\n",
      "Epoch 1060/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0077 - val_loss: 0.0272\n",
      "Epoch 1061/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0073 - val_loss: 0.0287\n",
      "Epoch 1062/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0071 - val_loss: 0.0316\n",
      "Epoch 1063/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0069 - val_loss: 0.0320\n",
      "Epoch 1064/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0074 - val_loss: 0.0295\n",
      "Epoch 1065/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0070 - val_loss: 0.0296\n",
      "Epoch 1066/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0070 - val_loss: 0.0285\n",
      "Epoch 1067/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0076 - val_loss: 0.0307\n",
      "Epoch 1068/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0070 - val_loss: 0.0272\n",
      "Epoch 1069/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0075 - val_loss: 0.0299\n",
      "Epoch 1070/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0084 - val_loss: 0.0338\n",
      "Epoch 1071/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0077 - val_loss: 0.0294\n",
      "Epoch 1072/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0075 - val_loss: 0.0306\n",
      "Epoch 1073/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0078 - val_loss: 0.0298\n",
      "Epoch 1074/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0067 - val_loss: 0.0303\n",
      "Epoch 1075/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0066 - val_loss: 0.0292\n",
      "Epoch 1076/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0071 - val_loss: 0.0303\n",
      "Epoch 1077/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0078 - val_loss: 0.0333\n",
      "Epoch 1078/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 306us/step - loss: 0.0070 - val_loss: 0.0252\n",
      "Epoch 1079/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0078 - val_loss: 0.0344\n",
      "Epoch 1080/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0076 - val_loss: 0.0329\n",
      "Epoch 1081/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0075 - val_loss: 0.0288\n",
      "Epoch 1082/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0077 - val_loss: 0.0306\n",
      "Epoch 1083/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0075 - val_loss: 0.0293\n",
      "Epoch 1084/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0074 - val_loss: 0.0317\n",
      "Epoch 1085/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0077 - val_loss: 0.0303\n",
      "Epoch 1086/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0076 - val_loss: 0.0279\n",
      "Epoch 1087/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0074 - val_loss: 0.0325\n",
      "Epoch 1088/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0075 - val_loss: 0.0280\n",
      "Epoch 1089/2000\n",
      "760/760 [==============================] - 0s 258us/step - loss: 0.0067 - val_loss: 0.0296\n",
      "Epoch 1090/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0072 - val_loss: 0.0297\n",
      "Epoch 1091/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0069 - val_loss: 0.0307\n",
      "Epoch 1092/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0074 - val_loss: 0.0351\n",
      "Epoch 1093/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0078 - val_loss: 0.0320\n",
      "Epoch 1094/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0067 - val_loss: 0.0262\n",
      "Epoch 1095/2000\n",
      "760/760 [==============================] - 0s 263us/step - loss: 0.0082 - val_loss: 0.0270\n",
      "Epoch 1096/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0071 - val_loss: 0.0279\n",
      "Epoch 1097/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0068 - val_loss: 0.0291\n",
      "Epoch 1098/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0069 - val_loss: 0.0294\n",
      "Epoch 1099/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0075 - val_loss: 0.0290\n",
      "Epoch 1100/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0065 - val_loss: 0.0272\n",
      "Epoch 1101/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0072 - val_loss: 0.0232\n",
      "Epoch 1102/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0074 - val_loss: 0.0308\n",
      "Epoch 1103/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0080 - val_loss: 0.0323\n",
      "Epoch 1104/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0071 - val_loss: 0.0290\n",
      "Epoch 1105/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0074 - val_loss: 0.0322\n",
      "Epoch 1106/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0078 - val_loss: 0.0306\n",
      "Epoch 1107/2000\n",
      "760/760 [==============================] - 0s 261us/step - loss: 0.0076 - val_loss: 0.0291\n",
      "Epoch 1108/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0074 - val_loss: 0.0272\n",
      "Epoch 1109/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0071 - val_loss: 0.0294\n",
      "Epoch 1110/2000\n",
      "760/760 [==============================] - ETA: 0s - loss: 0.007 - 0s 262us/step - loss: 0.0075 - val_loss: 0.0270\n",
      "Epoch 1111/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0073 - val_loss: 0.0289\n",
      "Epoch 1112/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0072 - val_loss: 0.0304\n",
      "Epoch 1113/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0305\n",
      "Epoch 1114/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0065 - val_loss: 0.0257\n",
      "Epoch 1115/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0074 - val_loss: 0.0277\n",
      "Epoch 1116/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0078 - val_loss: 0.0295\n",
      "Epoch 1117/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0069 - val_loss: 0.0282\n",
      "Epoch 1118/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0075 - val_loss: 0.0331\n",
      "Epoch 1119/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0077 - val_loss: 0.0284\n",
      "Epoch 1120/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0065 - val_loss: 0.0302\n",
      "Epoch 1121/2000\n",
      "760/760 [==============================] - 0s 259us/step - loss: 0.0063 - val_loss: 0.0284\n",
      "Epoch 1122/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0068 - val_loss: 0.0336\n",
      "Epoch 1123/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0068 - val_loss: 0.0299\n",
      "Epoch 1124/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0073 - val_loss: 0.0279\n",
      "Epoch 1125/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0078 - val_loss: 0.0312\n",
      "Epoch 1126/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0067 - val_loss: 0.0269\n",
      "Epoch 1127/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0069 - val_loss: 0.0316\n",
      "Epoch 1128/2000\n",
      "760/760 [==============================] - 0s 263us/step - loss: 0.0068 - val_loss: 0.0292\n",
      "Epoch 1129/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0072 - val_loss: 0.0286\n",
      "Epoch 1130/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0072 - val_loss: 0.0297\n",
      "Epoch 1131/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0075 - val_loss: 0.0319\n",
      "Epoch 1132/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0069 - val_loss: 0.0286\n",
      "Epoch 1133/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0075 - val_loss: 0.0250\n",
      "Epoch 1134/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0075 - val_loss: 0.0278\n",
      "Epoch 1135/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0064 - val_loss: 0.0283\n",
      "Epoch 1136/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0080 - val_loss: 0.0298\n",
      "Epoch 1137/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0075 - val_loss: 0.0323\n",
      "Epoch 1138/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0077 - val_loss: 0.0250\n",
      "Epoch 1139/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0069 - val_loss: 0.0241\n",
      "Epoch 1140/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0072 - val_loss: 0.0253\n",
      "Epoch 1141/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0305\n",
      "Epoch 1142/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0071 - val_loss: 0.0279\n",
      "Epoch 1143/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0299\n",
      "Epoch 1144/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0074 - val_loss: 0.0295\n",
      "Epoch 1145/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0074 - val_loss: 0.0253\n",
      "Epoch 1146/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0076 - val_loss: 0.0292\n",
      "Epoch 1147/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0067 - val_loss: 0.0287\n",
      "Epoch 1148/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0071 - val_loss: 0.0269\n",
      "Epoch 1149/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0074 - val_loss: 0.0263\n",
      "Epoch 1150/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0079 - val_loss: 0.0299\n",
      "Epoch 1151/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0069 - val_loss: 0.0270\n",
      "Epoch 1152/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0079 - val_loss: 0.0260\n",
      "Epoch 1153/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0074 - val_loss: 0.0262\n",
      "Epoch 1154/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0079 - val_loss: 0.0269\n",
      "Epoch 1155/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0071 - val_loss: 0.0263\n",
      "Epoch 1156/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0068 - val_loss: 0.0271\n",
      "Epoch 1157/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0076 - val_loss: 0.0274\n",
      "Epoch 1158/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0065 - val_loss: 0.0257\n",
      "Epoch 1159/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0078 - val_loss: 0.0286\n",
      "Epoch 1160/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0075 - val_loss: 0.0289\n",
      "Epoch 1161/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0071 - val_loss: 0.0272\n",
      "Epoch 1162/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0074 - val_loss: 0.0288\n",
      "Epoch 1163/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0072 - val_loss: 0.0279\n",
      "Epoch 1164/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0066 - val_loss: 0.0210\n",
      "Epoch 1165/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0075 - val_loss: 0.0268\n",
      "Epoch 1166/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0070 - val_loss: 0.0307\n",
      "Epoch 1167/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0073 - val_loss: 0.0275\n",
      "Epoch 1168/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0070 - val_loss: 0.0260\n",
      "Epoch 1169/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0065 - val_loss: 0.0250\n",
      "Epoch 1170/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0081 - val_loss: 0.0323\n",
      "Epoch 1171/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0079 - val_loss: 0.0268\n",
      "Epoch 1172/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0073 - val_loss: 0.0284\n",
      "Epoch 1173/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0074 - val_loss: 0.0250\n",
      "Epoch 1174/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0076 - val_loss: 0.0266\n",
      "Epoch 1175/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0075 - val_loss: 0.0292\n",
      "Epoch 1176/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0079 - val_loss: 0.0266\n",
      "Epoch 1177/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0073 - val_loss: 0.0298\n",
      "Epoch 1178/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0072 - val_loss: 0.0284\n",
      "Epoch 1179/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0071 - val_loss: 0.0268\n",
      "Epoch 1180/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0062 - val_loss: 0.0267\n",
      "Epoch 1181/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0062 - val_loss: 0.0278\n",
      "Epoch 1182/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0073 - val_loss: 0.0266\n",
      "Epoch 1183/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0070 - val_loss: 0.0278\n",
      "Epoch 1184/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0073 - val_loss: 0.0268\n",
      "Epoch 1185/2000\n",
      "760/760 [==============================] - 0s 250us/step - loss: 0.0075 - val_loss: 0.0281\n",
      "Epoch 1186/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0070 - val_loss: 0.0275\n",
      "Epoch 1187/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0065 - val_loss: 0.0267\n",
      "Epoch 1188/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0077 - val_loss: 0.0300\n",
      "Epoch 1189/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0080 - val_loss: 0.0285\n",
      "Epoch 1190/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0082 - val_loss: 0.0336\n",
      "Epoch 1191/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0078 - val_loss: 0.0329\n",
      "Epoch 1192/2000\n",
      "760/760 [==============================] - 0s 254us/step - loss: 0.0089 - val_loss: 0.0235\n",
      "Epoch 1193/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0072 - val_loss: 0.0263\n",
      "Epoch 1194/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0073 - val_loss: 0.0228\n",
      "Epoch 1195/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0082 - val_loss: 0.0248\n",
      "Epoch 1196/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0069 - val_loss: 0.0252\n",
      "Epoch 1197/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0077 - val_loss: 0.0265\n",
      "Epoch 1198/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0070 - val_loss: 0.0268\n",
      "Epoch 1199/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0070 - val_loss: 0.0257\n",
      "Epoch 1200/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0072 - val_loss: 0.0248\n",
      "Epoch 1201/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0076 - val_loss: 0.0301\n",
      "Epoch 1202/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0073 - val_loss: 0.0289\n",
      "Epoch 1203/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0070 - val_loss: 0.0278\n",
      "Epoch 1204/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0067 - val_loss: 0.0275\n",
      "Epoch 1205/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0081 - val_loss: 0.0301\n",
      "Epoch 1206/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0068 - val_loss: 0.0275\n",
      "Epoch 1207/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0072 - val_loss: 0.0262\n",
      "Epoch 1208/2000\n",
      "760/760 [==============================] - 0s 331us/step - loss: 0.0070 - val_loss: 0.0264\n",
      "Epoch 1209/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0065 - val_loss: 0.0280\n",
      "Epoch 1210/2000\n",
      "760/760 [==============================] - 0s 306us/step - loss: 0.0071 - val_loss: 0.0297\n",
      "Epoch 1211/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0068 - val_loss: 0.0291\n",
      "Epoch 1212/2000\n",
      "760/760 [==============================] - 0s 311us/step - loss: 0.0074 - val_loss: 0.0243\n",
      "Epoch 1213/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0070 - val_loss: 0.0283\n",
      "Epoch 1214/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0073 - val_loss: 0.0269\n",
      "Epoch 1215/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0073 - val_loss: 0.0281\n",
      "Epoch 1216/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0069 - val_loss: 0.0269\n",
      "Epoch 1217/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0077 - val_loss: 0.0285\n",
      "Epoch 1218/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0078 - val_loss: 0.0301\n",
      "Epoch 1219/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0081 - val_loss: 0.0326\n",
      "Epoch 1220/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0078 - val_loss: 0.0308\n",
      "Epoch 1221/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0071 - val_loss: 0.0295\n",
      "Epoch 1222/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0069 - val_loss: 0.0318\n",
      "Epoch 1223/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0065 - val_loss: 0.0307\n",
      "Epoch 1224/2000\n",
      "760/760 [==============================] - 0s 261us/step - loss: 0.0074 - val_loss: 0.0313\n",
      "Epoch 1225/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0074 - val_loss: 0.0290\n",
      "Epoch 1226/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0079 - val_loss: 0.0315\n",
      "Epoch 1227/2000\n",
      "760/760 [==============================] - 0s 260us/step - loss: 0.0074 - val_loss: 0.0313\n",
      "Epoch 1228/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0060 - val_loss: 0.0321\n",
      "Epoch 1229/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0070 - val_loss: 0.0273\n",
      "Epoch 1230/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 277us/step - loss: 0.0077 - val_loss: 0.0312\n",
      "Epoch 1231/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0064 - val_loss: 0.0293\n",
      "Epoch 1232/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0071 - val_loss: 0.0329\n",
      "Epoch 1233/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0072 - val_loss: 0.0280\n",
      "Epoch 1234/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0074 - val_loss: 0.0299\n",
      "Epoch 1235/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0292\n",
      "Epoch 1236/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0065 - val_loss: 0.0295\n",
      "Epoch 1237/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0063 - val_loss: 0.0283\n",
      "Epoch 1238/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0070 - val_loss: 0.0306\n",
      "Epoch 1239/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0072 - val_loss: 0.0273\n",
      "Epoch 1240/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0074 - val_loss: 0.0239\n",
      "Epoch 1241/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0073 - val_loss: 0.0320\n",
      "Epoch 1242/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0072 - val_loss: 0.0280\n",
      "Epoch 1243/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0077 - val_loss: 0.0306\n",
      "Epoch 1244/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0069 - val_loss: 0.0306\n",
      "Epoch 1245/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0076 - val_loss: 0.0308\n",
      "Epoch 1246/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0073 - val_loss: 0.0288\n",
      "Epoch 1247/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0072 - val_loss: 0.0283\n",
      "Epoch 1248/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0076 - val_loss: 0.0285\n",
      "Epoch 1249/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0065 - val_loss: 0.0280\n",
      "Epoch 1250/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0085 - val_loss: 0.0298\n",
      "Epoch 1251/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0076 - val_loss: 0.0294\n",
      "Epoch 1252/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0075 - val_loss: 0.0296\n",
      "Epoch 1253/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0070 - val_loss: 0.0299\n",
      "Epoch 1254/2000\n",
      "760/760 [==============================] - 0s 261us/step - loss: 0.0068 - val_loss: 0.0258\n",
      "Epoch 1255/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0074 - val_loss: 0.0260\n",
      "Epoch 1256/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0077 - val_loss: 0.0243\n",
      "Epoch 1257/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0076 - val_loss: 0.0297\n",
      "Epoch 1258/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0071 - val_loss: 0.0309\n",
      "Epoch 1259/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0082 - val_loss: 0.0281\n",
      "Epoch 1260/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0080 - val_loss: 0.0287\n",
      "Epoch 1261/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0084 - val_loss: 0.0274\n",
      "Epoch 1262/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0070 - val_loss: 0.0256\n",
      "Epoch 1263/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0070 - val_loss: 0.0246\n",
      "Epoch 1264/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0073 - val_loss: 0.0327\n",
      "Epoch 1265/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0075 - val_loss: 0.0299\n",
      "Epoch 1266/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0072 - val_loss: 0.0274\n",
      "Epoch 1267/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0071 - val_loss: 0.0243\n",
      "Epoch 1268/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0078 - val_loss: 0.0313\n",
      "Epoch 1269/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0079 - val_loss: 0.0270\n",
      "Epoch 1270/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0080 - val_loss: 0.0305\n",
      "Epoch 1271/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0074 - val_loss: 0.0300\n",
      "Epoch 1272/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0067 - val_loss: 0.0282\n",
      "Epoch 1273/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0072 - val_loss: 0.0243\n",
      "Epoch 1274/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0072 - val_loss: 0.0323\n",
      "Epoch 1275/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0073 - val_loss: 0.0263\n",
      "Epoch 1276/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0067 - val_loss: 0.0276\n",
      "Epoch 1277/2000\n",
      "760/760 [==============================] - 0s 254us/step - loss: 0.0079 - val_loss: 0.0320\n",
      "Epoch 1278/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0082 - val_loss: 0.0269\n",
      "Epoch 1279/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0073 - val_loss: 0.0264\n",
      "Epoch 1280/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0069 - val_loss: 0.0303\n",
      "Epoch 1281/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0072 - val_loss: 0.0251\n",
      "Epoch 1282/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0065 - val_loss: 0.0281\n",
      "Epoch 1283/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0074 - val_loss: 0.0268\n",
      "Epoch 1284/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0075 - val_loss: 0.0305\n",
      "Epoch 1285/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0079 - val_loss: 0.0249\n",
      "Epoch 1286/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0085 - val_loss: 0.0285\n",
      "Epoch 1287/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0072 - val_loss: 0.0310\n",
      "Epoch 1288/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0077 - val_loss: 0.0274\n",
      "Epoch 1289/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0072 - val_loss: 0.0253\n",
      "Epoch 1290/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0072 - val_loss: 0.0263\n",
      "Epoch 1291/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0072 - val_loss: 0.0248\n",
      "Epoch 1292/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0073 - val_loss: 0.0289\n",
      "Epoch 1293/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0072 - val_loss: 0.0301\n",
      "Epoch 1294/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0077 - val_loss: 0.0239\n",
      "Epoch 1295/2000\n",
      "760/760 [==============================] - 0s 308us/step - loss: 0.0074 - val_loss: 0.0284\n",
      "Epoch 1296/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0072 - val_loss: 0.0257\n",
      "Epoch 1297/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0067 - val_loss: 0.0275\n",
      "Epoch 1298/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0071 - val_loss: 0.0252\n",
      "Epoch 1299/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0075 - val_loss: 0.0255\n",
      "Epoch 1300/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0080 - val_loss: 0.0300\n",
      "Epoch 1301/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0075 - val_loss: 0.0310\n",
      "Epoch 1302/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0069 - val_loss: 0.0266\n",
      "Epoch 1303/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0070 - val_loss: 0.0302\n",
      "Epoch 1304/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0076 - val_loss: 0.0367\n",
      "Epoch 1305/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0075 - val_loss: 0.0292\n",
      "Epoch 1306/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0072 - val_loss: 0.0304\n",
      "Epoch 1307/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0076 - val_loss: 0.0276\n",
      "Epoch 1308/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0074 - val_loss: 0.0288\n",
      "Epoch 1309/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0069 - val_loss: 0.0286\n",
      "Epoch 1310/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0072 - val_loss: 0.0289\n",
      "Epoch 1311/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0070 - val_loss: 0.0270\n",
      "Epoch 1312/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0067 - val_loss: 0.0265\n",
      "Epoch 1313/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0075 - val_loss: 0.0225\n",
      "Epoch 1314/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0072 - val_loss: 0.0292\n",
      "Epoch 1315/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0075 - val_loss: 0.0288\n",
      "Epoch 1316/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0063 - val_loss: 0.0263\n",
      "Epoch 1317/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0067 - val_loss: 0.0274\n",
      "Epoch 1318/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0075 - val_loss: 0.0266\n",
      "Epoch 1319/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0074 - val_loss: 0.0272\n",
      "Epoch 1320/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0068 - val_loss: 0.0301\n",
      "Epoch 1321/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0062 - val_loss: 0.0300\n",
      "Epoch 1322/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0064 - val_loss: 0.0270\n",
      "Epoch 1323/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0064 - val_loss: 0.0281\n",
      "Epoch 1324/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0069 - val_loss: 0.0298\n",
      "Epoch 1325/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0068 - val_loss: 0.0265\n",
      "Epoch 1326/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0067 - val_loss: 0.0226\n",
      "Epoch 1327/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0064 - val_loss: 0.0233\n",
      "Epoch 1328/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0082 - val_loss: 0.0255\n",
      "Epoch 1329/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0072 - val_loss: 0.0258\n",
      "Epoch 1330/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0071 - val_loss: 0.0312\n",
      "Epoch 1331/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0066 - val_loss: 0.0288\n",
      "Epoch 1332/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0070 - val_loss: 0.0269\n",
      "Epoch 1333/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0069 - val_loss: 0.0282\n",
      "Epoch 1334/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0070 - val_loss: 0.0334\n",
      "Epoch 1335/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0072 - val_loss: 0.0265\n",
      "Epoch 1336/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0074 - val_loss: 0.0243\n",
      "Epoch 1337/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0073 - val_loss: 0.0247\n",
      "Epoch 1338/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0070 - val_loss: 0.0263\n",
      "Epoch 1339/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0073 - val_loss: 0.0277\n",
      "Epoch 1340/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0073 - val_loss: 0.0255\n",
      "Epoch 1341/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0074 - val_loss: 0.0258\n",
      "Epoch 1342/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0072 - val_loss: 0.0276\n",
      "Epoch 1343/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0071 - val_loss: 0.0270\n",
      "Epoch 1344/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0087 - val_loss: 0.0270\n",
      "Epoch 1345/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0069 - val_loss: 0.0271\n",
      "Epoch 1346/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0070 - val_loss: 0.0274\n",
      "Epoch 1347/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0063 - val_loss: 0.0257\n",
      "Epoch 1348/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0067 - val_loss: 0.0283\n",
      "Epoch 1349/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0070 - val_loss: 0.0273\n",
      "Epoch 1350/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0075 - val_loss: 0.0273\n",
      "Epoch 1351/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0068 - val_loss: 0.0311\n",
      "Epoch 1352/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0068 - val_loss: 0.0280\n",
      "Epoch 1353/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0070 - val_loss: 0.0279\n",
      "Epoch 1354/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0068 - val_loss: 0.0317\n",
      "Epoch 1355/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0077 - val_loss: 0.0353\n",
      "Epoch 1356/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0072 - val_loss: 0.0277\n",
      "Epoch 1357/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0070 - val_loss: 0.0282\n",
      "Epoch 1358/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0064 - val_loss: 0.0264\n",
      "Epoch 1359/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0072 - val_loss: 0.0328\n",
      "Epoch 1360/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0081 - val_loss: 0.0341\n",
      "Epoch 1361/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0069 - val_loss: 0.0296\n",
      "Epoch 1362/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0079 - val_loss: 0.0255\n",
      "Epoch 1363/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0075 - val_loss: 0.0277\n",
      "Epoch 1364/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0076 - val_loss: 0.0271\n",
      "Epoch 1365/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0070 - val_loss: 0.0286\n",
      "Epoch 1366/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0072 - val_loss: 0.0283\n",
      "Epoch 1367/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0069 - val_loss: 0.0279\n",
      "Epoch 1368/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0079 - val_loss: 0.0327\n",
      "Epoch 1369/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0065 - val_loss: 0.0280\n",
      "Epoch 1370/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0073 - val_loss: 0.0319\n",
      "Epoch 1371/2000\n",
      "760/760 [==============================] - 0s 258us/step - loss: 0.0073 - val_loss: 0.0288\n",
      "Epoch 1372/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0069 - val_loss: 0.0287\n",
      "Epoch 1373/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0074 - val_loss: 0.0296\n",
      "Epoch 1374/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0079 - val_loss: 0.0297\n",
      "Epoch 1375/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0314\n",
      "Epoch 1376/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0070 - val_loss: 0.0283\n",
      "Epoch 1377/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0067 - val_loss: 0.0279\n",
      "Epoch 1378/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0070 - val_loss: 0.0318\n",
      "Epoch 1379/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0074 - val_loss: 0.0325\n",
      "Epoch 1380/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0070 - val_loss: 0.0290\n",
      "Epoch 1381/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0069 - val_loss: 0.0268\n",
      "Epoch 1382/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 277us/step - loss: 0.0065 - val_loss: 0.0272\n",
      "Epoch 1383/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0076 - val_loss: 0.0252\n",
      "Epoch 1384/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0082 - val_loss: 0.0302\n",
      "Epoch 1385/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0073 - val_loss: 0.0303\n",
      "Epoch 1386/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0069 - val_loss: 0.0254\n",
      "Epoch 1387/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0069 - val_loss: 0.0272\n",
      "Epoch 1388/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0070 - val_loss: 0.0291\n",
      "Epoch 1389/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0073 - val_loss: 0.0299\n",
      "Epoch 1390/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0077 - val_loss: 0.0281\n",
      "Epoch 1391/2000\n",
      "760/760 [==============================] - 0s 260us/step - loss: 0.0072 - val_loss: 0.0256\n",
      "Epoch 1392/2000\n",
      "760/760 [==============================] - 0s 251us/step - loss: 0.0063 - val_loss: 0.0248\n",
      "Epoch 1393/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0074 - val_loss: 0.0302\n",
      "Epoch 1394/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0076 - val_loss: 0.0264\n",
      "Epoch 1395/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0068 - val_loss: 0.0255\n",
      "Epoch 1396/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0069 - val_loss: 0.0256\n",
      "Epoch 1397/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0072 - val_loss: 0.0282\n",
      "Epoch 1398/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0076 - val_loss: 0.0287\n",
      "Epoch 1399/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0068 - val_loss: 0.0262\n",
      "Epoch 1400/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0069 - val_loss: 0.0257\n",
      "Epoch 1401/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0073 - val_loss: 0.0282\n",
      "Epoch 1402/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0076 - val_loss: 0.0262\n",
      "Epoch 1403/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0074 - val_loss: 0.0257\n",
      "Epoch 1404/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0062 - val_loss: 0.0264\n",
      "Epoch 1405/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0071 - val_loss: 0.0246\n",
      "Epoch 1406/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0071 - val_loss: 0.0241\n",
      "Epoch 1407/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0075 - val_loss: 0.0236\n",
      "Epoch 1408/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0071 - val_loss: 0.0237\n",
      "Epoch 1409/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0075 - val_loss: 0.0272\n",
      "Epoch 1410/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0077 - val_loss: 0.0290\n",
      "Epoch 1411/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0074 - val_loss: 0.0215\n",
      "Epoch 1412/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0077 - val_loss: 0.0249\n",
      "Epoch 1413/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0063 - val_loss: 0.0275\n",
      "Epoch 1414/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0072 - val_loss: 0.0267\n",
      "Epoch 1415/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0077 - val_loss: 0.0280\n",
      "Epoch 1416/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0075 - val_loss: 0.0267\n",
      "Epoch 1417/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0068 - val_loss: 0.0237\n",
      "Epoch 1418/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0272\n",
      "Epoch 1419/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0076 - val_loss: 0.0270\n",
      "Epoch 1420/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0066 - val_loss: 0.0258\n",
      "Epoch 1421/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0075 - val_loss: 0.0298\n",
      "Epoch 1422/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0071 - val_loss: 0.0311\n",
      "Epoch 1423/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0071 - val_loss: 0.0290\n",
      "Epoch 1424/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0077 - val_loss: 0.0295\n",
      "Epoch 1425/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0068 - val_loss: 0.0336\n",
      "Epoch 1426/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0070 - val_loss: 0.0249\n",
      "Epoch 1427/2000\n",
      "760/760 [==============================] - 0s 257us/step - loss: 0.0078 - val_loss: 0.0289\n",
      "Epoch 1428/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0073 - val_loss: 0.0355\n",
      "Epoch 1429/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0080 - val_loss: 0.0289\n",
      "Epoch 1430/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0077 - val_loss: 0.0302\n",
      "Epoch 1431/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0074 - val_loss: 0.0319\n",
      "Epoch 1432/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0072 - val_loss: 0.0339\n",
      "Epoch 1433/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0077 - val_loss: 0.0299\n",
      "Epoch 1434/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0074 - val_loss: 0.0299\n",
      "Epoch 1435/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0076 - val_loss: 0.0291\n",
      "Epoch 1436/2000\n",
      "760/760 [==============================] - 0s 305us/step - loss: 0.0071 - val_loss: 0.0288\n",
      "Epoch 1437/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0073 - val_loss: 0.0297\n",
      "Epoch 1438/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0079 - val_loss: 0.0330\n",
      "Epoch 1439/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0077 - val_loss: 0.0281\n",
      "Epoch 1440/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0074 - val_loss: 0.0337\n",
      "Epoch 1441/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0069 - val_loss: 0.0314\n",
      "Epoch 1442/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0084 - val_loss: 0.0296\n",
      "Epoch 1443/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0072 - val_loss: 0.0271\n",
      "Epoch 1444/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0069 - val_loss: 0.0318\n",
      "Epoch 1445/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0068 - val_loss: 0.0344\n",
      "Epoch 1446/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0071 - val_loss: 0.0317\n",
      "Epoch 1447/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0066 - val_loss: 0.0281\n",
      "Epoch 1448/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0073 - val_loss: 0.0249\n",
      "Epoch 1449/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0067 - val_loss: 0.0308\n",
      "Epoch 1450/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0074 - val_loss: 0.0303\n",
      "Epoch 1451/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0070 - val_loss: 0.0272\n",
      "Epoch 1452/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0074 - val_loss: 0.0289\n",
      "Epoch 1453/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0069 - val_loss: 0.0268\n",
      "Epoch 1454/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0071 - val_loss: 0.0249\n",
      "Epoch 1455/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0074 - val_loss: 0.0307\n",
      "Epoch 1456/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0071 - val_loss: 0.0293\n",
      "Epoch 1457/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0064 - val_loss: 0.0255\n",
      "Epoch 1458/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0070 - val_loss: 0.0258\n",
      "Epoch 1459/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0069 - val_loss: 0.0297\n",
      "Epoch 1460/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0073 - val_loss: 0.0276\n",
      "Epoch 1461/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0075 - val_loss: 0.0269\n",
      "Epoch 1462/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0075 - val_loss: 0.0285\n",
      "Epoch 1463/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0065 - val_loss: 0.0279\n",
      "Epoch 1464/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0078 - val_loss: 0.0306\n",
      "Epoch 1465/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0074 - val_loss: 0.0250\n",
      "Epoch 1466/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0070 - val_loss: 0.0327\n",
      "Epoch 1467/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0077 - val_loss: 0.0275\n",
      "Epoch 1468/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0073 - val_loss: 0.0298\n",
      "Epoch 1469/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0070 - val_loss: 0.0281\n",
      "Epoch 1470/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0068 - val_loss: 0.0310\n",
      "Epoch 1471/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0066 - val_loss: 0.0304\n",
      "Epoch 1472/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0071 - val_loss: 0.0266\n",
      "Epoch 1473/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0070 - val_loss: 0.0304\n",
      "Epoch 1474/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0073 - val_loss: 0.0272\n",
      "Epoch 1475/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0066 - val_loss: 0.0280\n",
      "Epoch 1476/2000\n",
      "760/760 [==============================] - 0s 263us/step - loss: 0.0068 - val_loss: 0.0319\n",
      "Epoch 1477/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0076 - val_loss: 0.0243\n",
      "Epoch 1478/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0073 - val_loss: 0.0290\n",
      "Epoch 1479/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0071 - val_loss: 0.0268\n",
      "Epoch 1480/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0069 - val_loss: 0.0237\n",
      "Epoch 1481/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0071 - val_loss: 0.0265\n",
      "Epoch 1482/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0073 - val_loss: 0.0251\n",
      "Epoch 1483/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0069 - val_loss: 0.0288\n",
      "Epoch 1484/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0078 - val_loss: 0.0322\n",
      "Epoch 1485/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0073 - val_loss: 0.0294\n",
      "Epoch 1486/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0083 - val_loss: 0.0262\n",
      "Epoch 1487/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0069 - val_loss: 0.0291\n",
      "Epoch 1488/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0080 - val_loss: 0.0329\n",
      "Epoch 1489/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0068 - val_loss: 0.0280\n",
      "Epoch 1490/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0072 - val_loss: 0.0329\n",
      "Epoch 1491/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0083 - val_loss: 0.0290\n",
      "Epoch 1492/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0077 - val_loss: 0.0275\n",
      "Epoch 1493/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0070 - val_loss: 0.0274\n",
      "Epoch 1494/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0081 - val_loss: 0.0286\n",
      "Epoch 1495/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0069 - val_loss: 0.0269\n",
      "Epoch 1496/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0072 - val_loss: 0.0307\n",
      "Epoch 1497/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0074 - val_loss: 0.0283\n",
      "Epoch 1498/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0072 - val_loss: 0.0265\n",
      "Epoch 1499/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0071 - val_loss: 0.0293\n",
      "Epoch 1500/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0068 - val_loss: 0.0273\n",
      "Epoch 1501/2000\n",
      "760/760 [==============================] - 0s 261us/step - loss: 0.0069 - val_loss: 0.0327\n",
      "Epoch 1502/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0069 - val_loss: 0.0293\n",
      "Epoch 1503/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0295\n",
      "Epoch 1504/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0068 - val_loss: 0.0246\n",
      "Epoch 1505/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0078 - val_loss: 0.0237\n",
      "Epoch 1506/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0075 - val_loss: 0.0324\n",
      "Epoch 1507/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0077 - val_loss: 0.0341\n",
      "Epoch 1508/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0070 - val_loss: 0.0293\n",
      "Epoch 1509/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0074 - val_loss: 0.0268\n",
      "Epoch 1510/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0079 - val_loss: 0.0292\n",
      "Epoch 1511/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0076 - val_loss: 0.0255\n",
      "Epoch 1512/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0070 - val_loss: 0.0290\n",
      "Epoch 1513/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0070 - val_loss: 0.0290\n",
      "Epoch 1514/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0082 - val_loss: 0.0284\n",
      "Epoch 1515/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0076 - val_loss: 0.0305\n",
      "Epoch 1516/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0076 - val_loss: 0.0287\n",
      "Epoch 1517/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0076 - val_loss: 0.0261\n",
      "Epoch 1518/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0070 - val_loss: 0.0309\n",
      "Epoch 1519/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0074 - val_loss: 0.0276\n",
      "Epoch 1520/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0072 - val_loss: 0.0276\n",
      "Epoch 1521/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0072 - val_loss: 0.0232\n",
      "Epoch 1522/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0077 - val_loss: 0.0286\n",
      "Epoch 1523/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0062 - val_loss: 0.0283\n",
      "Epoch 1524/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0070 - val_loss: 0.0305\n",
      "Epoch 1525/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0072 - val_loss: 0.0346\n",
      "Epoch 1526/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0079 - val_loss: 0.0308\n",
      "Epoch 1527/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0069 - val_loss: 0.0311\n",
      "Epoch 1528/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0068 - val_loss: 0.0310\n",
      "Epoch 1529/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0068 - val_loss: 0.0263\n",
      "Epoch 1530/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0071 - val_loss: 0.0324\n",
      "Epoch 1531/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0070 - val_loss: 0.0321\n",
      "Epoch 1532/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0078 - val_loss: 0.0285\n",
      "Epoch 1533/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0074 - val_loss: 0.0285\n",
      "Epoch 1534/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 299us/step - loss: 0.0070 - val_loss: 0.0253\n",
      "Epoch 1535/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0076 - val_loss: 0.0273\n",
      "Epoch 1536/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0069 - val_loss: 0.0289\n",
      "Epoch 1537/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0070 - val_loss: 0.0275\n",
      "Epoch 1538/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0073 - val_loss: 0.0294\n",
      "Epoch 1539/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0071 - val_loss: 0.0288\n",
      "Epoch 1540/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0070 - val_loss: 0.0319\n",
      "Epoch 1541/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0069 - val_loss: 0.0325\n",
      "Epoch 1542/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0074 - val_loss: 0.0265\n",
      "Epoch 1543/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0074 - val_loss: 0.0304\n",
      "Epoch 1544/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0075 - val_loss: 0.0319\n",
      "Epoch 1545/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0073 - val_loss: 0.0219\n",
      "Epoch 1546/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0074 - val_loss: 0.0255\n",
      "Epoch 1547/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0077 - val_loss: 0.0307\n",
      "Epoch 1548/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0070 - val_loss: 0.0290\n",
      "Epoch 1549/2000\n",
      "760/760 [==============================] - 0s 260us/step - loss: 0.0066 - val_loss: 0.0309\n",
      "Epoch 1550/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0066 - val_loss: 0.0272\n",
      "Epoch 1551/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0068 - val_loss: 0.0261\n",
      "Epoch 1552/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0070 - val_loss: 0.0262\n",
      "Epoch 1553/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0071 - val_loss: 0.0251\n",
      "Epoch 1554/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0071 - val_loss: 0.0257\n",
      "Epoch 1555/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0070 - val_loss: 0.0309\n",
      "Epoch 1556/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0078 - val_loss: 0.0253\n",
      "Epoch 1557/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0076 - val_loss: 0.0328\n",
      "Epoch 1558/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0074 - val_loss: 0.0285\n",
      "Epoch 1559/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0078 - val_loss: 0.0260\n",
      "Epoch 1560/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0066 - val_loss: 0.0300\n",
      "Epoch 1561/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0072 - val_loss: 0.0304\n",
      "Epoch 1562/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0072 - val_loss: 0.0287\n",
      "Epoch 1563/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0071 - val_loss: 0.0274\n",
      "Epoch 1564/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0077 - val_loss: 0.0308\n",
      "Epoch 1565/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0079 - val_loss: 0.0269\n",
      "Epoch 1566/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0070 - val_loss: 0.0314\n",
      "Epoch 1567/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0075 - val_loss: 0.0272\n",
      "Epoch 1568/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0068 - val_loss: 0.0283\n",
      "Epoch 1569/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0068 - val_loss: 0.0283\n",
      "Epoch 1570/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0083 - val_loss: 0.0290\n",
      "Epoch 1571/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0074 - val_loss: 0.0266\n",
      "Epoch 1572/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0067 - val_loss: 0.0307\n",
      "Epoch 1573/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0067 - val_loss: 0.0278\n",
      "Epoch 1574/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0075 - val_loss: 0.0260\n",
      "Epoch 1575/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0066 - val_loss: 0.0285\n",
      "Epoch 1576/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0065 - val_loss: 0.0278\n",
      "Epoch 1577/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0284\n",
      "Epoch 1578/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0068 - val_loss: 0.0254\n",
      "Epoch 1579/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0071 - val_loss: 0.0310\n",
      "Epoch 1580/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0068 - val_loss: 0.0281\n",
      "Epoch 1581/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0080 - val_loss: 0.0293\n",
      "Epoch 1582/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0073 - val_loss: 0.0275\n",
      "Epoch 1583/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0067 - val_loss: 0.0282\n",
      "Epoch 1584/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0067 - val_loss: 0.0270\n",
      "Epoch 1585/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0068 - val_loss: 0.0263\n",
      "Epoch 1586/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0073 - val_loss: 0.0303\n",
      "Epoch 1587/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0072 - val_loss: 0.0277\n",
      "Epoch 1588/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0067 - val_loss: 0.0265\n",
      "Epoch 1589/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0078 - val_loss: 0.0286\n",
      "Epoch 1590/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0066 - val_loss: 0.0299\n",
      "Epoch 1591/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0074 - val_loss: 0.0291\n",
      "Epoch 1592/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0075 - val_loss: 0.0317\n",
      "Epoch 1593/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0070 - val_loss: 0.0310\n",
      "Epoch 1594/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0075 - val_loss: 0.0282\n",
      "Epoch 1595/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0071 - val_loss: 0.0268\n",
      "Epoch 1596/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0065 - val_loss: 0.0320\n",
      "Epoch 1597/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0075 - val_loss: 0.0321\n",
      "Epoch 1598/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0065 - val_loss: 0.0275\n",
      "Epoch 1599/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0067 - val_loss: 0.0301\n",
      "Epoch 1600/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0072 - val_loss: 0.0303\n",
      "Epoch 1601/2000\n",
      "760/760 [==============================] - 0s 258us/step - loss: 0.0079 - val_loss: 0.0313\n",
      "Epoch 1602/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0076 - val_loss: 0.0298\n",
      "Epoch 1603/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0071 - val_loss: 0.0266\n",
      "Epoch 1604/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0075 - val_loss: 0.0287\n",
      "Epoch 1605/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0066 - val_loss: 0.0270\n",
      "Epoch 1606/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0064 - val_loss: 0.0322\n",
      "Epoch 1607/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0068 - val_loss: 0.0324\n",
      "Epoch 1608/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0068 - val_loss: 0.0295\n",
      "Epoch 1609/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0076 - val_loss: 0.0313\n",
      "Epoch 1610/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0067 - val_loss: 0.0298\n",
      "Epoch 1611/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0068 - val_loss: 0.0311\n",
      "Epoch 1612/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0067 - val_loss: 0.0322\n",
      "Epoch 1613/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0068 - val_loss: 0.0296\n",
      "Epoch 1614/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0072 - val_loss: 0.0276\n",
      "Epoch 1615/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0072 - val_loss: 0.0275\n",
      "Epoch 1616/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0066 - val_loss: 0.0284\n",
      "Epoch 1617/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0079 - val_loss: 0.0303\n",
      "Epoch 1618/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0077 - val_loss: 0.0298\n",
      "Epoch 1619/2000\n",
      "760/760 [==============================] - 0s 264us/step - loss: 0.0064 - val_loss: 0.0318\n",
      "Epoch 1620/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0060 - val_loss: 0.0294\n",
      "Epoch 1621/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0066 - val_loss: 0.0309\n",
      "Epoch 1622/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0069 - val_loss: 0.0277\n",
      "Epoch 1623/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0081 - val_loss: 0.0304\n",
      "Epoch 1624/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0074 - val_loss: 0.0292\n",
      "Epoch 1625/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0076 - val_loss: 0.0298\n",
      "Epoch 1626/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0075 - val_loss: 0.0273\n",
      "Epoch 1627/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0077 - val_loss: 0.0245\n",
      "Epoch 1628/2000\n",
      "760/760 [==============================] - 0s 304us/step - loss: 0.0069 - val_loss: 0.0303\n",
      "Epoch 1629/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0077 - val_loss: 0.0317\n",
      "Epoch 1630/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0067 - val_loss: 0.0259\n",
      "Epoch 1631/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0076 - val_loss: 0.0296\n",
      "Epoch 1632/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0323\n",
      "Epoch 1633/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0070 - val_loss: 0.0348\n",
      "Epoch 1634/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0069 - val_loss: 0.0314\n",
      "Epoch 1635/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0064 - val_loss: 0.0294\n",
      "Epoch 1636/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0061 - val_loss: 0.0275\n",
      "Epoch 1637/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0068 - val_loss: 0.0273\n",
      "Epoch 1638/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0076 - val_loss: 0.0308\n",
      "Epoch 1639/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0065 - val_loss: 0.0277\n",
      "Epoch 1640/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0066 - val_loss: 0.0311\n",
      "Epoch 1641/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0063 - val_loss: 0.0320\n",
      "Epoch 1642/2000\n",
      "760/760 [==============================] - 0s 252us/step - loss: 0.0070 - val_loss: 0.0326\n",
      "Epoch 1643/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0070 - val_loss: 0.0286\n",
      "Epoch 1644/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0071 - val_loss: 0.0298\n",
      "Epoch 1645/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0072 - val_loss: 0.0305\n",
      "Epoch 1646/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0070 - val_loss: 0.0248\n",
      "Epoch 1647/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0067 - val_loss: 0.0260\n",
      "Epoch 1648/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0080 - val_loss: 0.0272\n",
      "Epoch 1649/2000\n",
      "760/760 [==============================] - 0s 260us/step - loss: 0.0076 - val_loss: 0.0264\n",
      "Epoch 1650/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0068 - val_loss: 0.0308\n",
      "Epoch 1651/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0079 - val_loss: 0.0265\n",
      "Epoch 1652/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0074 - val_loss: 0.0257\n",
      "Epoch 1653/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0061 - val_loss: 0.0265\n",
      "Epoch 1654/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0074 - val_loss: 0.0249\n",
      "Epoch 1655/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0076 - val_loss: 0.0271\n",
      "Epoch 1656/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0068 - val_loss: 0.0260\n",
      "Epoch 1657/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0315\n",
      "Epoch 1658/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0064 - val_loss: 0.0275\n",
      "Epoch 1659/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0065 - val_loss: 0.0298\n",
      "Epoch 1660/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0072 - val_loss: 0.0313\n",
      "Epoch 1661/2000\n",
      "760/760 [==============================] - 0s 250us/step - loss: 0.0068 - val_loss: 0.0318\n",
      "Epoch 1662/2000\n",
      "760/760 [==============================] - 0s 263us/step - loss: 0.0070 - val_loss: 0.0250\n",
      "Epoch 1663/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0076 - val_loss: 0.0279\n",
      "Epoch 1664/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0069 - val_loss: 0.0257\n",
      "Epoch 1665/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0078 - val_loss: 0.0298\n",
      "Epoch 1666/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0072 - val_loss: 0.0294\n",
      "Epoch 1667/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0071 - val_loss: 0.0289\n",
      "Epoch 1668/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0074 - val_loss: 0.0305\n",
      "Epoch 1669/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0071 - val_loss: 0.0267\n",
      "Epoch 1670/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0081 - val_loss: 0.0244\n",
      "Epoch 1671/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0067 - val_loss: 0.0292\n",
      "Epoch 1672/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0072 - val_loss: 0.0257\n",
      "Epoch 1673/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0061 - val_loss: 0.0290\n",
      "Epoch 1674/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0081 - val_loss: 0.0278\n",
      "Epoch 1675/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0076 - val_loss: 0.0285\n",
      "Epoch 1676/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0070 - val_loss: 0.0253\n",
      "Epoch 1677/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0069 - val_loss: 0.0277\n",
      "Epoch 1678/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0074 - val_loss: 0.0283\n",
      "Epoch 1679/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0064 - val_loss: 0.0261\n",
      "Epoch 1680/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0075 - val_loss: 0.0288\n",
      "Epoch 1681/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0077 - val_loss: 0.0304\n",
      "Epoch 1682/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0077 - val_loss: 0.0213\n",
      "Epoch 1683/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0071 - val_loss: 0.0259\n",
      "Epoch 1684/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0066 - val_loss: 0.0303\n",
      "Epoch 1685/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0078 - val_loss: 0.0256\n",
      "Epoch 1686/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 307us/step - loss: 0.0074 - val_loss: 0.0298\n",
      "Epoch 1687/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0075 - val_loss: 0.0230\n",
      "Epoch 1688/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0064 - val_loss: 0.0248\n",
      "Epoch 1689/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0074 - val_loss: 0.0268\n",
      "Epoch 1690/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0073 - val_loss: 0.0275\n",
      "Epoch 1691/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0070 - val_loss: 0.0259\n",
      "Epoch 1692/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0072 - val_loss: 0.0282\n",
      "Epoch 1693/2000\n",
      "760/760 [==============================] - 0s 262us/step - loss: 0.0072 - val_loss: 0.0229\n",
      "Epoch 1694/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0066 - val_loss: 0.0248\n",
      "Epoch 1695/2000\n",
      "760/760 [==============================] - 0s 253us/step - loss: 0.0072 - val_loss: 0.0244\n",
      "Epoch 1696/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0073 - val_loss: 0.0307\n",
      "Epoch 1697/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0081 - val_loss: 0.0300\n",
      "Epoch 1698/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0069 - val_loss: 0.0229\n",
      "Epoch 1699/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0076 - val_loss: 0.0269\n",
      "Epoch 1700/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0087 - val_loss: 0.0270\n",
      "Epoch 1701/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0073 - val_loss: 0.0269\n",
      "Epoch 1702/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0074 - val_loss: 0.0304\n",
      "Epoch 1703/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0084 - val_loss: 0.0305\n",
      "Epoch 1704/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0243\n",
      "Epoch 1705/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0076 - val_loss: 0.0257\n",
      "Epoch 1706/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0069 - val_loss: 0.0281\n",
      "Epoch 1707/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0070 - val_loss: 0.0313\n",
      "Epoch 1708/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0079 - val_loss: 0.0278\n",
      "Epoch 1709/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0069 - val_loss: 0.0276\n",
      "Epoch 1710/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0078 - val_loss: 0.0285\n",
      "Epoch 1711/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0064 - val_loss: 0.0304\n",
      "Epoch 1712/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0068 - val_loss: 0.0241\n",
      "Epoch 1713/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0072 - val_loss: 0.0264\n",
      "Epoch 1714/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0075 - val_loss: 0.0272\n",
      "Epoch 1715/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0067 - val_loss: 0.0302\n",
      "Epoch 1716/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0074 - val_loss: 0.0285\n",
      "Epoch 1717/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0070 - val_loss: 0.0290\n",
      "Epoch 1718/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0069 - val_loss: 0.0312\n",
      "Epoch 1719/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0064 - val_loss: 0.0267\n",
      "Epoch 1720/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0071 - val_loss: 0.0304\n",
      "Epoch 1721/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0079 - val_loss: 0.0270\n",
      "Epoch 1722/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0071 - val_loss: 0.0294\n",
      "Epoch 1723/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0066 - val_loss: 0.0314\n",
      "Epoch 1724/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0065 - val_loss: 0.0333\n",
      "Epoch 1725/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0075 - val_loss: 0.0274\n",
      "Epoch 1726/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0067 - val_loss: 0.0267\n",
      "Epoch 1727/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0073 - val_loss: 0.0251\n",
      "Epoch 1728/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0075 - val_loss: 0.0303\n",
      "Epoch 1729/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0072 - val_loss: 0.0294\n",
      "Epoch 1730/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0064 - val_loss: 0.0277\n",
      "Epoch 1731/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0079 - val_loss: 0.0334\n",
      "Epoch 1732/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0077 - val_loss: 0.0245\n",
      "Epoch 1733/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0073 - val_loss: 0.0280\n",
      "Epoch 1734/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0073 - val_loss: 0.0288\n",
      "Epoch 1735/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0263\n",
      "Epoch 1736/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0071 - val_loss: 0.0264\n",
      "Epoch 1737/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0071 - val_loss: 0.0285\n",
      "Epoch 1738/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0072 - val_loss: 0.0278\n",
      "Epoch 1739/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0069 - val_loss: 0.0279\n",
      "Epoch 1740/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0072 - val_loss: 0.0283\n",
      "Epoch 1741/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0073 - val_loss: 0.0309\n",
      "Epoch 1742/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0070 - val_loss: 0.0262\n",
      "Epoch 1743/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0080 - val_loss: 0.0268\n",
      "Epoch 1744/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0071 - val_loss: 0.0248\n",
      "Epoch 1745/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0070 - val_loss: 0.0283\n",
      "Epoch 1746/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0064 - val_loss: 0.0312\n",
      "Epoch 1747/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0072 - val_loss: 0.0283\n",
      "Epoch 1748/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0075 - val_loss: 0.0283\n",
      "Epoch 1749/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0069 - val_loss: 0.0331\n",
      "Epoch 1750/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0073 - val_loss: 0.0289\n",
      "Epoch 1751/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0074 - val_loss: 0.0321\n",
      "Epoch 1752/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0069 - val_loss: 0.0294\n",
      "Epoch 1753/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0073 - val_loss: 0.0291\n",
      "Epoch 1754/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0065 - val_loss: 0.0286\n",
      "Epoch 1755/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0061 - val_loss: 0.0273\n",
      "Epoch 1756/2000\n",
      "760/760 [==============================] - 0s 306us/step - loss: 0.0077 - val_loss: 0.0289\n",
      "Epoch 1757/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0066 - val_loss: 0.0287\n",
      "Epoch 1758/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0070 - val_loss: 0.0317\n",
      "Epoch 1759/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0075 - val_loss: 0.0326\n",
      "Epoch 1760/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0075 - val_loss: 0.0318\n",
      "Epoch 1761/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0067 - val_loss: 0.0262\n",
      "Epoch 1762/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0065 - val_loss: 0.0282\n",
      "Epoch 1763/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0065 - val_loss: 0.0269\n",
      "Epoch 1764/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0062 - val_loss: 0.0268\n",
      "Epoch 1765/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0074 - val_loss: 0.0311\n",
      "Epoch 1766/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0075 - val_loss: 0.0293\n",
      "Epoch 1767/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0067 - val_loss: 0.0290\n",
      "Epoch 1768/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0067 - val_loss: 0.0338\n",
      "Epoch 1769/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0073 - val_loss: 0.0270\n",
      "Epoch 1770/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0074 - val_loss: 0.0289\n",
      "Epoch 1771/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0078 - val_loss: 0.0302\n",
      "Epoch 1772/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0068 - val_loss: 0.0259\n",
      "Epoch 1773/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0069 - val_loss: 0.0271\n",
      "Epoch 1774/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0069 - val_loss: 0.0309\n",
      "Epoch 1775/2000\n",
      "760/760 [==============================] - 0s 313us/step - loss: 0.0075 - val_loss: 0.0303\n",
      "Epoch 1776/2000\n",
      "760/760 [==============================] - 0s 331us/step - loss: 0.0079 - val_loss: 0.0325\n",
      "Epoch 1777/2000\n",
      "760/760 [==============================] - 0s 302us/step - loss: 0.0075 - val_loss: 0.0217\n",
      "Epoch 1778/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0082 - val_loss: 0.0260\n",
      "Epoch 1779/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0081 - val_loss: 0.0255\n",
      "Epoch 1780/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0078 - val_loss: 0.0229\n",
      "Epoch 1781/2000\n",
      "760/760 [==============================] - 0s 269us/step - loss: 0.0066 - val_loss: 0.0251\n",
      "Epoch 1782/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0069 - val_loss: 0.0269\n",
      "Epoch 1783/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0273\n",
      "Epoch 1784/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0075 - val_loss: 0.0275\n",
      "Epoch 1785/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0075 - val_loss: 0.0274\n",
      "Epoch 1786/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0074 - val_loss: 0.0259\n",
      "Epoch 1787/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0070 - val_loss: 0.0278\n",
      "Epoch 1788/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0067 - val_loss: 0.0276\n",
      "Epoch 1789/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0059 - val_loss: 0.0282\n",
      "Epoch 1790/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0069 - val_loss: 0.0282\n",
      "Epoch 1791/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0072 - val_loss: 0.0238\n",
      "Epoch 1792/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0064 - val_loss: 0.0329\n",
      "Epoch 1793/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0074 - val_loss: 0.0286\n",
      "Epoch 1794/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0069 - val_loss: 0.0249\n",
      "Epoch 1795/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0081 - val_loss: 0.0270\n",
      "Epoch 1796/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0073 - val_loss: 0.0296\n",
      "Epoch 1797/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0065 - val_loss: 0.0310\n",
      "Epoch 1798/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0064 - val_loss: 0.0274\n",
      "Epoch 1799/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0066 - val_loss: 0.0286\n",
      "Epoch 1800/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0069 - val_loss: 0.0273\n",
      "Epoch 1801/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0069 - val_loss: 0.0283\n",
      "Epoch 1802/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0066 - val_loss: 0.0307\n",
      "Epoch 1803/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0072 - val_loss: 0.0276\n",
      "Epoch 1804/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0069 - val_loss: 0.0301\n",
      "Epoch 1805/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0068 - val_loss: 0.0293\n",
      "Epoch 1806/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0068 - val_loss: 0.0310\n",
      "Epoch 1807/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0074 - val_loss: 0.0311\n",
      "Epoch 1808/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0066 - val_loss: 0.0313\n",
      "Epoch 1809/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0074 - val_loss: 0.0280\n",
      "Epoch 1810/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0076 - val_loss: 0.0272\n",
      "Epoch 1811/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0067 - val_loss: 0.0297\n",
      "Epoch 1812/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0067 - val_loss: 0.0322\n",
      "Epoch 1813/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0067 - val_loss: 0.0292\n",
      "Epoch 1814/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0070 - val_loss: 0.0254\n",
      "Epoch 1815/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0075 - val_loss: 0.0319\n",
      "Epoch 1816/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0296\n",
      "Epoch 1817/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0072 - val_loss: 0.0306\n",
      "Epoch 1818/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0072 - val_loss: 0.0259\n",
      "Epoch 1819/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0069 - val_loss: 0.0273\n",
      "Epoch 1820/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0070 - val_loss: 0.0299\n",
      "Epoch 1821/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0073 - val_loss: 0.0285\n",
      "Epoch 1822/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0063 - val_loss: 0.0276\n",
      "Epoch 1823/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0073 - val_loss: 0.0263\n",
      "Epoch 1824/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0080 - val_loss: 0.0272\n",
      "Epoch 1825/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0080 - val_loss: 0.0327\n",
      "Epoch 1826/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0075 - val_loss: 0.0266\n",
      "Epoch 1827/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0077 - val_loss: 0.0221\n",
      "Epoch 1828/2000\n",
      "760/760 [==============================] - 0s 301us/step - loss: 0.0073 - val_loss: 0.0250\n",
      "Epoch 1829/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0070 - val_loss: 0.0253\n",
      "Epoch 1830/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0065 - val_loss: 0.0284\n",
      "Epoch 1831/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0065 - val_loss: 0.0273\n",
      "Epoch 1832/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0076 - val_loss: 0.0274\n",
      "Epoch 1833/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0071 - val_loss: 0.0261\n",
      "Epoch 1834/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0079 - val_loss: 0.0269\n",
      "Epoch 1835/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0263\n",
      "Epoch 1836/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0072 - val_loss: 0.0285\n",
      "Epoch 1837/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0071 - val_loss: 0.0273\n",
      "Epoch 1838/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0306\n",
      "Epoch 1839/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0072 - val_loss: 0.0270\n",
      "Epoch 1840/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0070 - val_loss: 0.0297\n",
      "Epoch 1841/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0076 - val_loss: 0.0260\n",
      "Epoch 1842/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0074 - val_loss: 0.0273\n",
      "Epoch 1843/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0067 - val_loss: 0.0287\n",
      "Epoch 1844/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0066 - val_loss: 0.0283\n",
      "Epoch 1845/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0072 - val_loss: 0.0312\n",
      "Epoch 1846/2000\n",
      "760/760 [==============================] - 0s 290us/step - loss: 0.0073 - val_loss: 0.0263\n",
      "Epoch 1847/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0070 - val_loss: 0.0264\n",
      "Epoch 1848/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0069 - val_loss: 0.0277\n",
      "Epoch 1849/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0071 - val_loss: 0.0274\n",
      "Epoch 1850/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0077 - val_loss: 0.0287\n",
      "Epoch 1851/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0069 - val_loss: 0.0289\n",
      "Epoch 1852/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0071 - val_loss: 0.0288\n",
      "Epoch 1853/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0068 - val_loss: 0.0309\n",
      "Epoch 1854/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0065 - val_loss: 0.0285\n",
      "Epoch 1855/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0062 - val_loss: 0.0292\n",
      "Epoch 1856/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0067 - val_loss: 0.0248\n",
      "Epoch 1857/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0072 - val_loss: 0.0265\n",
      "Epoch 1858/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0073 - val_loss: 0.0286\n",
      "Epoch 1859/2000\n",
      "760/760 [==============================] - 0s 313us/step - loss: 0.0070 - val_loss: 0.0286\n",
      "Epoch 1860/2000\n",
      "760/760 [==============================] - 0s 311us/step - loss: 0.0071 - val_loss: 0.0291\n",
      "Epoch 1861/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0070 - val_loss: 0.0275\n",
      "Epoch 1862/2000\n",
      "760/760 [==============================] - 0s 297us/step - loss: 0.0069 - val_loss: 0.0253\n",
      "Epoch 1863/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0070 - val_loss: 0.0284\n",
      "Epoch 1864/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0070 - val_loss: 0.0300\n",
      "Epoch 1865/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0069 - val_loss: 0.0305\n",
      "Epoch 1866/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0066 - val_loss: 0.0251\n",
      "Epoch 1867/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0071 - val_loss: 0.0271\n",
      "Epoch 1868/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0068 - val_loss: 0.0257\n",
      "Epoch 1869/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0073 - val_loss: 0.0344\n",
      "Epoch 1870/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0077 - val_loss: 0.0275\n",
      "Epoch 1871/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0078 - val_loss: 0.0224\n",
      "Epoch 1872/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0078 - val_loss: 0.0267\n",
      "Epoch 1873/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0076 - val_loss: 0.0256\n",
      "Epoch 1874/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0070 - val_loss: 0.0266\n",
      "Epoch 1875/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0301\n",
      "Epoch 1876/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0077 - val_loss: 0.0275\n",
      "Epoch 1877/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0074 - val_loss: 0.0284\n",
      "Epoch 1878/2000\n",
      "760/760 [==============================] - 0s 256us/step - loss: 0.0069 - val_loss: 0.0303\n",
      "Epoch 1879/2000\n",
      "760/760 [==============================] - 0s 256us/step - loss: 0.0077 - val_loss: 0.0264\n",
      "Epoch 1880/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0075 - val_loss: 0.0286\n",
      "Epoch 1881/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0299\n",
      "Epoch 1882/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0069 - val_loss: 0.0314\n",
      "Epoch 1883/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0067 - val_loss: 0.0289\n",
      "Epoch 1884/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0074 - val_loss: 0.0260\n",
      "Epoch 1885/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0062 - val_loss: 0.0260\n",
      "Epoch 1886/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0077 - val_loss: 0.0319\n",
      "Epoch 1887/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0064 - val_loss: 0.0286\n",
      "Epoch 1888/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0071 - val_loss: 0.0288\n",
      "Epoch 1889/2000\n",
      "760/760 [==============================] - 0s 260us/step - loss: 0.0070 - val_loss: 0.0291\n",
      "Epoch 1890/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0076 - val_loss: 0.0272\n",
      "Epoch 1891/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0081 - val_loss: 0.0285\n",
      "Epoch 1892/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0078 - val_loss: 0.0247\n",
      "Epoch 1893/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0069 - val_loss: 0.0274\n",
      "Epoch 1894/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0073 - val_loss: 0.0293\n",
      "Epoch 1895/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0067 - val_loss: 0.0265\n",
      "Epoch 1896/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0065 - val_loss: 0.0255\n",
      "Epoch 1897/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0067 - val_loss: 0.0244\n",
      "Epoch 1898/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0069 - val_loss: 0.0244\n",
      "Epoch 1899/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0072 - val_loss: 0.0254\n",
      "Epoch 1900/2000\n",
      "760/760 [==============================] - 0s 270us/step - loss: 0.0069 - val_loss: 0.0275\n",
      "Epoch 1901/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0072 - val_loss: 0.0274\n",
      "Epoch 1902/2000\n",
      "760/760 [==============================] - 0s 289us/step - loss: 0.0076 - val_loss: 0.0268\n",
      "Epoch 1903/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0068 - val_loss: 0.0295\n",
      "Epoch 1904/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0068 - val_loss: 0.0250\n",
      "Epoch 1905/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0069 - val_loss: 0.0271\n",
      "Epoch 1906/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0067 - val_loss: 0.0293\n",
      "Epoch 1907/2000\n",
      "760/760 [==============================] - 0s 292us/step - loss: 0.0071 - val_loss: 0.0333\n",
      "Epoch 1908/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0076 - val_loss: 0.0289\n",
      "Epoch 1909/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0071 - val_loss: 0.0300\n",
      "Epoch 1910/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0069 - val_loss: 0.0301\n",
      "Epoch 1911/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0067 - val_loss: 0.0303\n",
      "Epoch 1912/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0073 - val_loss: 0.0318\n",
      "Epoch 1913/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0076 - val_loss: 0.0301\n",
      "Epoch 1914/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0071 - val_loss: 0.0292\n",
      "Epoch 1915/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0071 - val_loss: 0.0298\n",
      "Epoch 1916/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0074 - val_loss: 0.0298\n",
      "Epoch 1917/2000\n",
      "760/760 [==============================] - 0s 275us/step - loss: 0.0063 - val_loss: 0.0282\n",
      "Epoch 1918/2000\n",
      "760/760 [==============================] - 0s 279us/step - loss: 0.0074 - val_loss: 0.0273\n",
      "Epoch 1919/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0065 - val_loss: 0.0267\n",
      "Epoch 1920/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0069 - val_loss: 0.0295\n",
      "Epoch 1921/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0073 - val_loss: 0.0273\n",
      "Epoch 1922/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0069 - val_loss: 0.0278\n",
      "Epoch 1923/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0073 - val_loss: 0.0259\n",
      "Epoch 1924/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0067 - val_loss: 0.0270\n",
      "Epoch 1925/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0071 - val_loss: 0.0260\n",
      "Epoch 1926/2000\n",
      "760/760 [==============================] - 0s 299us/step - loss: 0.0067 - val_loss: 0.0265\n",
      "Epoch 1927/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0071 - val_loss: 0.0261\n",
      "Epoch 1928/2000\n",
      "760/760 [==============================] - 0s 250us/step - loss: 0.0070 - val_loss: 0.0287\n",
      "Epoch 1929/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0072 - val_loss: 0.0290\n",
      "Epoch 1930/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0076 - val_loss: 0.0295\n",
      "Epoch 1931/2000\n",
      "760/760 [==============================] - 0s 303us/step - loss: 0.0071 - val_loss: 0.0294\n",
      "Epoch 1932/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0072 - val_loss: 0.0265\n",
      "Epoch 1933/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0068 - val_loss: 0.0295\n",
      "Epoch 1934/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0073 - val_loss: 0.0256\n",
      "Epoch 1935/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0071 - val_loss: 0.0288\n",
      "Epoch 1936/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0064 - val_loss: 0.0265\n",
      "Epoch 1937/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0069 - val_loss: 0.0259\n",
      "Epoch 1938/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0064 - val_loss: 0.0276\n",
      "Epoch 1939/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0076 - val_loss: 0.0284\n",
      "Epoch 1940/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0069 - val_loss: 0.0266\n",
      "Epoch 1941/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0073 - val_loss: 0.0276\n",
      "Epoch 1942/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0074 - val_loss: 0.0286\n",
      "Epoch 1943/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0079 - val_loss: 0.0240\n",
      "Epoch 1944/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0081 - val_loss: 0.0275\n",
      "Epoch 1945/2000\n",
      "760/760 [==============================] - 0s 293us/step - loss: 0.0066 - val_loss: 0.0266\n",
      "Epoch 1946/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0073 - val_loss: 0.0270\n",
      "Epoch 1947/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0065 - val_loss: 0.0301\n",
      "Epoch 1948/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0076 - val_loss: 0.0273\n",
      "Epoch 1949/2000\n",
      "760/760 [==============================] - 0s 271us/step - loss: 0.0070 - val_loss: 0.0259\n",
      "Epoch 1950/2000\n",
      "760/760 [==============================] - 0s 276us/step - loss: 0.0070 - val_loss: 0.0332\n",
      "Epoch 1951/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0067 - val_loss: 0.0269\n",
      "Epoch 1952/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0075 - val_loss: 0.0288\n",
      "Epoch 1953/2000\n",
      "760/760 [==============================] - 0s 294us/step - loss: 0.0082 - val_loss: 0.0299\n",
      "Epoch 1954/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0066 - val_loss: 0.0286\n",
      "Epoch 1955/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0079 - val_loss: 0.0302\n",
      "Epoch 1956/2000\n",
      "760/760 [==============================] - 0s 298us/step - loss: 0.0078 - val_loss: 0.0283\n",
      "Epoch 1957/2000\n",
      "760/760 [==============================] - 0s 284us/step - loss: 0.0071 - val_loss: 0.0277\n",
      "Epoch 1958/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0069 - val_loss: 0.0289\n",
      "Epoch 1959/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0064 - val_loss: 0.0286\n",
      "Epoch 1960/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0070 - val_loss: 0.0268\n",
      "Epoch 1961/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0064 - val_loss: 0.0284\n",
      "Epoch 1962/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0068 - val_loss: 0.0308\n",
      "Epoch 1963/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0063 - val_loss: 0.0245\n",
      "Epoch 1964/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0074 - val_loss: 0.0269\n",
      "Epoch 1965/2000\n",
      "760/760 [==============================] - 0s 287us/step - loss: 0.0080 - val_loss: 0.0316\n",
      "Epoch 1966/2000\n",
      "760/760 [==============================] - 0s 272us/step - loss: 0.0072 - val_loss: 0.0298\n",
      "Epoch 1967/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0070 - val_loss: 0.0314\n",
      "Epoch 1968/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0072 - val_loss: 0.0284\n",
      "Epoch 1969/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0069 - val_loss: 0.0271\n",
      "Epoch 1970/2000\n",
      "760/760 [==============================] - 0s 300us/step - loss: 0.0071 - val_loss: 0.0262\n",
      "Epoch 1971/2000\n",
      "760/760 [==============================] - 0s 268us/step - loss: 0.0069 - val_loss: 0.0265\n",
      "Epoch 1972/2000\n",
      "760/760 [==============================] - 0s 273us/step - loss: 0.0068 - val_loss: 0.0243\n",
      "Epoch 1973/2000\n",
      "760/760 [==============================] - 0s 267us/step - loss: 0.0062 - val_loss: 0.0321\n",
      "Epoch 1974/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0075 - val_loss: 0.0295\n",
      "Epoch 1975/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0064 - val_loss: 0.0277\n",
      "Epoch 1976/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0079 - val_loss: 0.0309\n",
      "Epoch 1977/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0072 - val_loss: 0.0268\n",
      "Epoch 1978/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0070 - val_loss: 0.0258\n",
      "Epoch 1979/2000\n",
      "760/760 [==============================] - 0s 280us/step - loss: 0.0069 - val_loss: 0.0348\n",
      "Epoch 1980/2000\n",
      "760/760 [==============================] - 0s 265us/step - loss: 0.0072 - val_loss: 0.0310\n",
      "Epoch 1981/2000\n",
      "760/760 [==============================] - 0s 282us/step - loss: 0.0071 - val_loss: 0.0295\n",
      "Epoch 1982/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0077 - val_loss: 0.0278\n",
      "Epoch 1983/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0075 - val_loss: 0.0233\n",
      "Epoch 1984/2000\n",
      "760/760 [==============================] - 0s 307us/step - loss: 0.0070 - val_loss: 0.0270\n",
      "Epoch 1985/2000\n",
      "760/760 [==============================] - 0s 295us/step - loss: 0.0064 - val_loss: 0.0313\n",
      "Epoch 1986/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0072 - val_loss: 0.0289\n",
      "Epoch 1987/2000\n",
      "760/760 [==============================] - 0s 283us/step - loss: 0.0068 - val_loss: 0.0285\n",
      "Epoch 1988/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0071 - val_loss: 0.0309\n",
      "Epoch 1989/2000\n",
      "760/760 [==============================] - 0s 274us/step - loss: 0.0066 - val_loss: 0.0273\n",
      "Epoch 1990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s 272us/step - loss: 0.0071 - val_loss: 0.0249\n",
      "Epoch 1991/2000\n",
      "760/760 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0323\n",
      "Epoch 1992/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0075 - val_loss: 0.0255\n",
      "Epoch 1993/2000\n",
      "760/760 [==============================] - 0s 296us/step - loss: 0.0069 - val_loss: 0.0278\n",
      "Epoch 1994/2000\n",
      "760/760 [==============================] - 0s 281us/step - loss: 0.0070 - val_loss: 0.0254\n",
      "Epoch 1995/2000\n",
      "760/760 [==============================] - 0s 285us/step - loss: 0.0082 - val_loss: 0.0295\n",
      "Epoch 1996/2000\n",
      "760/760 [==============================] - 0s 288us/step - loss: 0.0067 - val_loss: 0.0266\n",
      "Epoch 1997/2000\n",
      "760/760 [==============================] - 0s 277us/step - loss: 0.0075 - val_loss: 0.0278\n",
      "Epoch 1998/2000\n",
      "760/760 [==============================] - 0s 278us/step - loss: 0.0076 - val_loss: 0.0310\n",
      "Epoch 1999/2000\n",
      "760/760 [==============================] - 0s 266us/step - loss: 0.0075 - val_loss: 0.0272\n",
      "Epoch 2000/2000\n",
      "760/760 [==============================] - 0s 291us/step - loss: 0.0068 - val_loss: 0.0241\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "hist = model.fit(x_train, y_train, epochs=2000, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa13027b828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check train \n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 0.15)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.02448586219872691\n",
      "Validation Score:  0.02405622784151799\n",
      "Test Score: 0.02405622784151799\n"
     ]
    }
   ],
   "source": [
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train Score: ', trainScore)\n",
    "valScore = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Validation Score: ', valScore)\n",
    "testScore = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Score:', testScore) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1308a0f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "look_ahead = 250\n",
    "xhat = x_test[0, None]\n",
    "predictions = np.zeros((look_ahead, 1))\n",
    "for i in range(look_ahead):     \n",
    "    prediction = model.predict(xhat, batch_size=32)\n",
    "    predictions[i] = prediction \n",
    "    xhat = np.hstack([xhat[:,1:], prediction])\n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(np.arange(look_ahead), predictions, 'r', label='prediction')\n",
    "plt.plot(np.arange(look_ahead), y_test[:look_ahead], label='test function')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
